% Edit by: Xiao Xing
% !TEX root = ./main.tex

\chapter{大数定律与中心极限定理}
大数定律与中心极限定理

\section{特征函数}

设 $ p (x) $ 是随机变量 $ X $ 的密度函数,
则 $ p (x) $ 的傅里叶变换是
\begin{equation*}
    \varphi (t) = \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x,
\end{equation*}
其中 $ i = \sqrt{-1} $ 是虚数单位.
由数学期望的概念知,
$ \varphi (t) $ 恰好是 $ E \bigl( \ee^{itx} \bigr) $.
这就是本节要讨论的特征函数,
它是处理许多概率论问题的有力工具,
它能把寻求独立随机变量和的分布的卷积运算 (积分运算) 转换成乘法运算,
还能把求分布的各阶原点矩 (积分运算) 转换成微分运算.
特别它能把寻求随机变量序列的极限分布转换成一般的函数极限问题,
下面从特征函数的定义开始介绍它们.

\subsection{特征函数的定义}

\begin{definition}{}{4.1.1}
    设 $ X $ 是一个随机变量,
    称
    \begin{equation}\label{eq:4.1.1}
        \varphi (t) = E \bigl( \ee^{itx} \bigr), \; -\infty \leq t \leq +\infty,
    \end{equation}
    为 $ X $ 的\textbf{特征函数}\index{特征函数}.
\end{definition}

因为 $ \lvert \ee^{itx} \rvert \leq 1 $,
所以 $ E \bigl( \ee^{itX} \bigr) $ 总是存在的,
即任一随机变量的特征函数总是存在的.

当离散随机变量 $ X $ 的分布列为 $ p_k = P ( X = x_k ) $, $ k = 1,2,\dotsc $,
则 $ X $ 的特征函数为
\begin{equation}\label{eq:4.1.2}
    \varphi (t) = \sum_{k=1}^{+\infty} \ee^{itx_k} p_k, \; -\infty \leq t \leq +\infty.
\end{equation}

当连续随机变量 $ X $ 的密度函数为 $ p (x) $,
则 $ X $ 的特征函数为
\begin{equation}\label{eq:4.1.3}
    \varphi (t) = \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x, \; -\infty \leq t \leq +\infty.
\end{equation}

与随机变量的数学期望、方差及各阶矩一样,
特征函数只依赖于随机变量的分布,
分布相同则特征函数也相同,
所以我们也常称为某\textbf{分布的特征函数}\index{特征函数!分布的特征函数}.


\begin{example}\label{exam:4.1.1}
    常用分布的特征函数
    \begin{enumerate}
        \item
        \textbf{单点分布}\index{分布!单点分布}: $ P (X = a) = 1 $, 
        其特征函数为
        \begin{equation*}
            \varphi (t) = \ee^{itz}.
        \end{equation*}
        \item\label{exam:4.1.1.2}
        \textbf{0-1分布}\index{分布!0-1分布}: $ P( X = x ) = p^x  ( 1 - p )^{1 - x} $, $ x = 0,1 $,
        其特征函数为
        \begin{equation*}
            \varphi (t) = p \ee^{it} + q, \quad \text{其中} \ q= 1 - p.
        \end{equation*}
        \item
        \textbf{泊松分布}\index{分布!泊松分布}: $ P ( X = k ) = ( \lambda^k/k! ) \ee^{-\lambda} $, $ k = 0, 1, \dotsc $, 其特征函数为
        \begin{equation*}
            \varphi (t) = \sum_{k=0}^{+\infty} \ee^{ikt} \frac{\lambda^k}{k!} \ee^{-\lambda} = \ee^{\lambda} \ee^{\lambda \ee^{it}} = \ee^{\lambda ( \ee^{it} ) -1}.
        \end{equation*}
        \item
        \textbf{均匀分布}\index{分布!均匀分布} $ U ( a,b ) $: 因为密度函数为
        \begin{equation*}
            p (x) = 
            \begin{cases}
                \dfrac{1}{b-a}, & a < x < b,\\
                0, & \text{其他}.
            \end{cases}
        \end{equation*}
        所以特征函数为
        \begin{equation*}
            \varphi (t) = \int_a^b \frac{\ee^{itx}}{b - a} \dd x = \frac{\ee^{ibt} - \ee^{iat}}{it (b-a)}.
        \end{equation*}
        \item
        \textbf{标准正态分布}\index{分布!标准正态分布} $ N (0,1) $: 因为密度函数为
        \begin{equation*}
            p (x) = \frac{1}{\sqrt{2\pi}} \exp \left( -\frac{x^2}{2} \right), \quad - \infty < x < + \infty.
        \end{equation*}
        所以特征函数为
        \begin{align*}
            \varphi (t) & = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} \exp \left( itx - \frac{x^2}{2} \right) \dd x\\
            & = \exp \left( -\frac{t^2}{2} \right) \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} \exp \left( -\frac{( x - it )^2}{2} \right) \dd x\\
            & = \exp \left( -\frac{t^2}{2} \right) \frac{1}{\sqrt{2\pi}} \int_{-\infty -it}^{+\infty -it} \exp \left( -\frac{x^2}{2} \right) \dd x\\
            & = \exp \left( -\frac{t^2}{2} \right),
        \end{align*}
        其中
        \begin{equation*}
            \int_{-\infty -it}^{+\infty -it} \exp \left( -\frac{x^2}{2} \right) \dd x = \sqrt{2\pi}
        \end{equation*}
        是利用复变函数中的围道积分求得的.
        有了标准正态分布的特征函数,
        再利用下节给出的特征函数的性质,
        就很容易得到一般正态分布 $ N ( \mu, \sigma^2 ) $ 的特征函数,
        见例~\ref{exam:4.1.2}.
        \item
        \textbf{指数分布}\index{分布!指数分布} $ Exp ( \lambda ) $: 因为密度函数为
        \begin{equation*}
            p (x) =
            \begin{cases}
                \lambda \ee^{-\lambda x}, & x > 0,\\
                0, & x \leq 0.
            \end{cases}
        \end{equation*}
        所以特征函数为
        \begin{align*}
            \varphi (t) & = \int_0^{+\infty} \ee^{itx} \lambda \ee^{-\lambda x} \dd x\\
            & = \lambda \left( \int_0^{+\infty} \cos (tx) \ee^{-\lambda x} \dd x + i \int_0^{+\infty} \sin (tx) \ee^{-\lambda x} \dd x \right)\\
            & = \lambda \left( \frac{\lambda}{\lambda^2 + t^2} + i \frac{t}{\lambda^2 + t^2} \right)\\
            & = \left( 1 - \frac{it}{\lambda} \right)^{-1}.
        \end{align*}
        以上积分中用到了复变函数中的欧拉公式: $ \ee^{itx} = \cos (tx) + i \sin ( tx) $.
    \end{enumerate}
\end{example}

\subsection{特征函数的性质}

现在我们来研究特征函数的一些性质,
其中 $ \varphi_X (t) $ 表示 $ X $ 的特征函数,
其他类似.

\begin{property}\label{prop:4.1.1}
    \begin{equation}\label{eq:4.1.4}
        \lvert \varphi (t) \rvert \leq \varphi (0) = 1.
    \end{equation}
\end{property}

\begin{property}\label{prop:4.1.2}
    \begin{equation}\label{eq:4.1.5}
        \varphi (-t) = \overline{\varphi (t)},
    \end{equation}
    其中 $ \overline{\varphi (t)} $ 表示 $ \varphi (t) $ 的共轭.
\end{property}

\begin{property}\label{prop:4.1.3}
    若 $ Y = aX + b $, 其中 $ a,b $ 是常数, 则
    \begin{equation}\label{eq:4.1.6}
        \varphi_Y (t) = \ee^{ibt} \varphi_X (at).
    \end{equation}
\end{property}

\begin{property}\label{prop:4.1.4}
    独立随机变量和的特征函数为特征函数的积,
    即设 $ X $ 与 $ Y $ 相互独立, 则
    \begin{equation}\label{eq:4.1.7}
        \varphi_{X+Y} (t) = \varphi_X (t) \cdot \varphi_Y (t).
    \end{equation}
\end{property}

\begin{property}\label{prop:4.1.5}
    若 $ E (x^l) $ 存在,
    则 $ X $ 的特征函数 $ \varphi(t) $ 可 $ l $ 次求导,
    且对 $ 1 \leq k \leq l $, 有
    \begin{equation}\label{eq:4.1.8}
        \varphi^{(k)} (0) = i^k E ( X^k ).
    \end{equation}
    上式提供了一条求随机变量的各阶矩的途径,
    特别可用下式去求数学期望和方差.
    \begin{equation}\label{eq:4.1.9}
        E (X) = \frac{\varphi' (0)}{i}, \quad \mathrm{Var} (X) = - \varphi'' (0) + \bigl( \varphi' (0) \bigr)^2.
    \end{equation}
\end{property}

\begin{proof}
    在此我们仅对连续场合进行证明,
    而在离散场合的证明是类似的.
    \begin{enumerate}
        \item 
        \begin{align*}
            \lvert \varphi (t) \rvert & = \left\lvert \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x \right\rvert 
            \leq \int_{-\infty}^{+\infty} \left\lvert \ee^{itx} \right\rvert p (x) \dd x\\
            & = \int_{-\infty}^{+\infty} p (x) \dd x
            = \varphi (0)
            = 1.
        \end{align*}
        \item 
        \begin{equation*}
            \varphi (-t) = \int_{-\infty}^{+\infty} \ee^{-itx} p (x) \dd x
            = \overline{\int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x}
            = \overline{\varphi (t)}.
        \end{equation*}
        \item
        \begin{equation*}
            \varphi_Y (t) = E ( \ee^{it (aX + b)} )
            = \ee^{ibt} E ( \ee^{iatX} ) = \ee^{ibt} \varphi (at).
        \end{equation*}
        \item
        因为 $ X $ 与 $ Y $ 相互独立, 所以 $ \ee^{itX} $ 与 $ \ee^{itY} $ 也是独立的, 从而有
        \begin{equation*}
            E \left( \ee^{it ( X + Y )} \right) = E \left( \ee^{itX} \ee^{itY} \right) = \varphi_X (t) \cdot \varphi_Y (t).
        \end{equation*}
        \item
        因为 $ E \left( X^l \right) $ 存在, 也就是
        \begin{equation*}
            \int_{-\infty}^{+\infty} \lvert x \rvert^l p (x) \dd x < +\infty,
        \end{equation*}
        于是含参变量 $ t $ 的广义积分 $ \int_{-\infty}^{+\infty} \ee^{itx} p(x) \dd x $ 可以对 $ t $ 求导 $ l $ 次, 于是对 $ 0 \leq k \leq l $, 有
        \begin{equation*}
            \varphi ^{(k)} (t) = \int_{-\infty}^{+\infty} i^k x^k \ee^{itx} p (x) \dd x = i^k E \left( X^k \ee^{itX} \right).
        \end{equation*}
        令 $ t = 0 $ 即得
        \begin{equation*}
            \varphi^{(k)} (0) = i^k E \left( X^k \right).
        \end{equation*}
    \end{enumerate}
    至此上述5条性质全部得证.
\end{proof}

下例是利用 \eqref{eq:4.1.6} 和 \eqref{eq:4.1.7} 来求一些常用分布的特征函数.


\begin{example}\label{exam:4.1.2}
    常用分布的特征函数 (二)

    \begin{enumerate}
        \item
        \textbf{二项分布}\index{分布!二项分布} $ b (n, p) $: 设 $ Y \sim b (n, p) $, 则 $ Y = X_1 + x_2 + \dotsb X_n $, 其中诸 $ X_i $ 是相互独立同分布的随机变量, 且 $ X_{i} \sim b (1, p) $, 由 例~\ref{exam:4.1.2} \ref{exam:4.1.1.2} 知
        \begin{equation*}
            \varphi_{X_i} (t) = p \ee^{it} + q,
        \end{equation*}
        所以由独立随机变量和的特征函数为特征函数的积, 得
        \begin{equation*}
            \varphi_Y (t) = \left( p \ee^{it} + q \right)^{\pi}
        \end{equation*}
        \item
        \textbf{正态分布}\index{分布!正态分布} $ N (\mu, \sigma^2) $: 设 $ Y \sim N (\mu, \sigma^2) $, 则 $ X = (Y - \mu) / \sigma \sim N (0, 1) $.
        由例~\ref{exam:4.1.1} 知
        \begin{equation*}
            \varphi_{X} (t) = \exp \left( -\frac{t^2}{2} \right).
        \end{equation*}
        所以由 $ Y = \sigma X + \mu $ 得
        \begin{equation*}
            \varphi_Y (t) = \varphi_{\alpha X + \mu} (t) =\ee^{i \mu t} \varphi_X ( \sigma t ) = \exp \left( i \mu t - \frac{\sigma^2 t^2}{2} \right).
        \end{equation*}
        \item 
        \textbf{伽玛分布}\index{分布!伽玛分布} $ Ga ( n, \lambda ) $: 设 $ Y \sim Ga ( n, \lambda ) $, 则$ Y = X_1 + X_2 + \dotsb + X_n $, 其中 $ X_i $ 独立同分布, 且 $ X_i \sim Exp ( \lambda ) $.
        由例~\ref{exam:4.1.1} 知
        \begin{equation*}
            \varphi_{X_i} (t) = \left( 1 - \frac{it}{\lambda} \right)^{-1}.
        \end{equation*}
        所以由独立随机变量和的特征函数为特征函数的积, 得
        \begin{equation*}
            \varphi_Y (t) = \left( \varphi_{X_i} (t) \right)^n = \left( 1 - \frac{it}{\lambda} \right)^{-n}.
        \end{equation*}
        进一步, 当 $ a $为任一正实数时, 我们可得 $ Ga ( n, \lambda ) $ 分布的特征函数为
        \begin{equation*}
            \varphi(t) = \left( 1 - \frac{it}{\lambda} \right)^{-a}.
        \end{equation*}
        \item
        $ \mathbf{\chi^2 (n)} $ \textbf{分布}\index{分布!chi2分布@$ \mathbf{\chi^2 (n)} $ 分布}: 因为 $ \chi^2 (n) = Ga ( n/2, 1/2 ) $, 所以 $ \chi^2 (n) $ 分布的特征函数为
        \begin{equation*}
            \varphi (t) = ( 1 - 2it )^{-n/2}.
        \end{equation*}
    \end{enumerate}
\end{example}

上述常用分布的特征函数汇总在表~\ref{tab:4.1.1} 中.

\begin{table}
    \renewcommand{\arraystretch}{1.6}
    \centering
    \caption{常用分布的特征函数}\label{tab:4.1.1}
    \begin{tabular}{>{\centering\arraybackslash}m{0.15\linewidth}>{\centering\arraybackslash}m{0.45\linewidth}>{\centering\arraybackslash}m{0.3\linewidth}}
        \toprule
        分布 & 分布列 $ p_k $ 或分布密度 $ p (x) $ & 特征函数 $ \varphi (t) $\\
        \midrule
        单点分布 & $ P (X = a) = 1 $ & $ \ee^{itz} $\\
        0-1分布 & $ P_k = p^k  q^{1 - k} $, $ k = 0,1 $ & $ p \ee^{it} + q $\\
        二项分布 $ b (n, p) $ & $ p_k = \binom{n}{k} p^k q^{1-k} $, $ k = 0,1,\dotsc,n $ & $ \left( p \ee^{it} + q \right)^{\pi} $\\
        泊松分布 $ P (\lambda) $ & $ P_k = ( \lambda^k/k! ) \ee^{-\lambda} $, $ k = 0, 1, \dotsc $ & $ \ee^{\lambda ( \ee^{it} ) -1} $\\
        均匀分布 $ U (a,b) $ & $ p (x) = 1/(b-a) $, $ a \leq x \leq b $ & $ \dfrac{\ee^{ibt} - \ee^{iat}}{it (b-a)} $\\
        正态分布 $ N (\mu, \sigma^2) $ & $ p (x) = \dfrac{1}{\sqrt{2\pi}\sigma} \exp \left( - \dfrac{( x - \mu )^2}{2 \sigma^2} \right) $ & $ \exp \left( i \mu t - \dfrac{\sigma^2 t^2}{2} \right) $\\
        指数分布 $ Exp ( \lambda ) $ & $ p (x) = \lambda \ee^{-\lambda x} $, $ x > 0 $ & $ \left( 1 - \dfrac{it}{\lambda} \right)^{-1} $\\
        伽玛分布 $ Ga ( a, \lambda ) $ & $ p (x) = \dfrac{\lambda^\alpha}{\Gamma (a)} x^{\alpha - 1} \ee^{-\lambda x} $, $ x \geq 0 $ & $ \left( 1 - \dfrac{it}{\lambda} \right)^{-a} $\\
        $ \chi^2 (n) $ 分布 & $ p (x) = \dfrac{x^{n/2 - 1} \ee^{-x/2}}{\Gamma (n/2) 2^{n/2}} $, $ x > 0 $ & $ ( 1 - 2it )^{-n/2} $\\
        \bottomrule
    \end{tabular}
\end{table}

下例是利用 \eqref{eq:4.1.8} 来求分布的数学期望和方差.

\begin{example}\label{exam:4.1.3}
    试利用特征函数的方法求伽玛分布 $ Ga ( n, \lambda ) $ 的数学期望和方差.
\end{example}

\begin{solution}
    因为伽玛分布 $ Ga ( a, \lambda ) $ 的特征函数及其一、二阶导数为
    \begin{gather*}
        \varphi (t) = \left( 1 - \dfrac{it}{\lambda} \right)^{-a},\\
        \varphi' (t) = \frac{ai}{\lambda} \left( 1 - \frac{it}{\lambda} \right)^{-a-1}, \ \varphi' (0) = \frac{ai}{\lambda},\\
        \varphi'' (t) = \frac{a ( a + 1 ) i^2}{\lambda^2} \left( 1 - \frac{it}{\lambda} \right)^{-a-2}, \ \varphi'' (0) = -\frac{a (a+1)}{\lambda^2},
    \end{gather*}
    所以由 \eqref{eq:4.1.9} 得
    \begin{align*}
        E (X) & = \frac{\varphi' (0)}{i} = \frac{a}{\lambda},\\
        Var (X) & = - \varphi'' (0) + \bigl( \varphi' (0) \bigr)^2 = \frac{a (a+1)}{\lambda^2} + \left( \frac{ai}{\lambda} \right)^2\\
        & = \frac{a (a+1)}{\lambda^2} - \frac{a^2}{\lambda^2} = \frac{a}{\lambda^2}.
    \end{align*}
\end{solution}

特征函数还有以下一些优良性质.

\begin{theorem}{一致连续性}{4.1.1}
    随机变量 $ X $ 的特征函数 $ \varphi (t) $ 在 $ ( -\infty, +\infty ) $ 上一致连续.
\end{theorem}

\begin{proof}
    设 $ X $ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $ p (x) $, 则对任意实数 $t$, $h$ 和正数$ a > 0 $, 有
    \begin{align*}
        \lvert \varphi ( t + h ) - \varphi (t) \rvert & = \left\lvert \int_{-\infty}^{+\infty} \bigl( \ee^{ihx} - 1 \bigr) \ee^{itx} p (x) \dd x \right\rvert\\
        & \leq \int_{-\infty}^{+\infty} \bigl\lvert \ee^{ihx} - 1 \bigr\rvert p (x) \dd x\\
        & \leq \int_{-a}^a \bigl\lvert \ee^{ihx} - 1 \bigr\rvert p (x) \dd x + 2 \int_{\lvert x \rvert \geq a} p (x) \dd x.
    \end{align*}
    对任意的 $ \varepsilon > 0 $, 先取定一个充分大的 $ a $, 使得
    \begin{equation*}
        2 \int_{\lvert x \rvert \geq a} p (x) \dd x < \frac{\varepsilon}{2},
    \end{equation*}
    然后对任意的$ x \in [-a,a] $, 只要取$ \delta = \varepsilon/(2a) $, 则当$ \lvert h \rvert < \delta $ 时, 便有
    \begin{align*}
        \lvert \ee^{ihx} - 1 \rvert & = \left\lvert \ee^{i \frac{h}{2} x} \left( \ee^{i \frac{h}{2} x} - \ee^{-i \frac{h}{2} x} \right) \right\rvert\\
        & = 2 \left\lvert \sin \frac{hx}{2} \right\rvert
        \leq 2 \left\lvert \frac{hx}{2} \right\rvert
        < ha
        < \frac{\varepsilon}{2},
    \end{align*}
    即 $ \varphi (t) $ 在 $ (-\infty, +\infty) $ 上一致连续.
\end{proof}

\begin{theorem}{非负定性}{4.1.2}
    随机变量 $ X $ 的特征函数 $ \varphi (t) $ 是非负定的, 即对任意正整数 $ n $, 及 $ n $ 个实数 $ t_1, t_2, \dotsc, t_n $ 和 $ n $ 个复数 $ z_1, z_2, \dotsc, z_n $, 有
    \begin{equation}\label{eq:4.1.10}
        \sum_{k=1}^n \sum_{j=1}^n \varphi ( t_k - t_j ) z_k \overline{z_j} \geq 0.
    \end{equation}
\end{theorem}

\begin{proof}
    仍设 $ X $ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $ p (x) $, 则有
    \begin{align*}
        \sum_{k=1}^n \sum_{j=1}^n \varphi ( t_k - t_j ) z_k \overline{z_j}
        & = \sum_{k=1}^n \sum_{j=1}^n z_k \overline{z_j} \int_{-\infty}^{+\infty} \ee^{i (t_k - t_j) x} p (x) \dd x\\
        & = \int_{-\infty}^{+\infty} \sum_{k=1}^n \sum_{j=1}^n z_k \overline{z_j} \ee^{i (t_k - t_j) x} p (x) \dd x\\
        & = \int_{-\infty}^{+\infty} \left( \sum_{k=1}^n z_k \ee^{i t_k x} \right) \left( \sum_{j=1}^n \overline{z_j} \ee^{-i t_j x} \right) p (x) \dd x\\
        & = \int_{-\infty}^{+\infty} \left\lvert \sum_{k=1}^n z_k \ee^{i t_k x} \right\lvert^2 p (x) \dd x \geq 0.
    \end{align*}
    这就证明了 \eqref{eq:4.1.10} 式.
\end{proof}

由特征函数的定义可知, 随机变量的分布惟一地确定了它的特征函数.
前面的讨论实际上都是从随机变量的分布出发, 讨论特征函数及其性质.
要注意的是: 如果两个分布的数学期望、方差及各阶矩都相等, 也无法证明此两个分布相等.
但特征函数却不同, 它有着比数学期望、方差及各阶矩更优良的性质: 即特征函数也完全决定了分布, 也就是说, 两个分布函数相等当且仅当它们所对应的特征函数相等.

以下定理~\ref{thm:4.1.3} 给出了由特征函数求分布函数的公式, 定理~\ref{thm:4.1.5} 给出了连续随机变量时由特征函数求密度函数的公式.
而定理~\ref{thm:4.1.4} 说明了分布函数与特征函数是一一对应的.

\begin{theorem}{逆转公式}{4.1.3}
    设 $ F (x) $ 和 $ \varphi (t) $ 分别为随机变量 $ X $ 的分布函数和特征函数, 则对 $ F (x) $ 的任意两个连续点 $ x_1 < x_2 $, 有
    \begin{equation}\label{eq:4.1.11}
        F (x_2) - F (x_1) = \lim_{T \to \infty} \frac{1}{2\pi} \int_{-T}^T \frac{\ee^{-itx_1}  - \ee^{-itx_2}}{it} \varphi (t) \dd t.
    \end{equation}
\end{theorem}

\begin{proof}
    设 $ X $ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $ p (x) $ .
    记
    \begin{align*}
        J_T & = \frac{1}{2\pi} \int_{-T}^T \frac{\ee^{-itx_1}  - \ee^{-itx_2}}{it} \varphi (t) \dd t\\
        & = \frac{1}{2\pi} \int_{-T}^T \left[ \int_{-\infty}^{+\infty} \frac{\ee^{-itx_1}  - \ee^{-itx_2}}{it} \ee^{itx} p (x) \right] \dd t.
    \end{align*}
    对任意的实数 $ a $, 有
    \begin{equation*}
        \left\lvert \ee^{ia} -1 \right\rvert \leq \lvert a \rvert,
    \end{equation*}
    事实上, 对 $ a \geq 0 $ 有
    \begin{equation*}
        \left\lvert \ee^{ia} - 1 \right\rvert = \left\lvert \int_0^t \ee^{ix} \dd x \right\rvert \leq \int_0^a \left\lvert \ee^{ix} \right\rvert \dd x = 0.
    \end{equation*}
    对 $ a < 0 $, 有
    \begin{equation*}
        \left\lvert \ee^{ia} - 1 \right\rvert = \left\lvert \ee^{ia} \left( \ee^{\lvert a \rvert} - 1 \right) \right\rvert = \left\lvert \ee^{i \lvert a \rvert} - 1 \right\rvert \leq \lvert a \rvert.
    \end{equation*}
    因此
    \begin{equation*}
        \left\lvert \frac{\ee^{-itx_1} - \ee^{-itx_2}}{it} \ee^{itx} \right\rvert \leq x_2 - x_1.
    \end{equation*}
    即 $ J_T $ 中被积函数有界, 所以可以交换积分次序, 从而得
    \begin{align*}
        J_T & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \left[ \int_{-T}^{T} \frac{\ee^{-itx_1} - \ee^{-itx_2}}{it} \ee^{itx} \dd t \right] p (x) \dd x\\
        & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \left[ \int_{0}^{T} \frac{\ee^{it(x - x_1)} - \ee^{-it (x - x_1)} - \ee^{it (x - x_2)} + \ee^{-it (x - x_2)}}{it} \dd t \right] p (x) \dd x\\
        & = \frac{1}{\pi} \int_{-\infty}^{+\infty} \left[ \int_{0}^{T} \left(\frac{\sin t (x - x_1)}{t} - \frac{\sin t (x - x_2)}{t} \right) \dd t \right] p (x) \dd x.
    \end{align*}
    又记
    \begin{equation*}
        g (T, x, x_1, x_2) = \frac{1}{\pi} \int_{0}^{T} \left(\frac{\sin t (x - x_1)}{t} - \frac{\sin t (x - x_2)}{t} \right) \dd t,
    \end{equation*}
    则由数学中的狄利克雷积分
    \begin{equation*}
        D (a) = \frac{1}{\pi} \int_0^{+\infty} \frac{\sin at}{t} \dd t =
        \begin{cases}
            \dfrac{1}{2}, & a > 0,\\
            0, & a = 0,\\
            -\dfrac{1}{2}, & a < 0.
        \end{cases}
    \end{equation*}
    知
    \begin{equation*}
        \lim_{t \to +\infty} g (T, x, x_1, x_2) = D (x - x_1) - D (x - x_2).
    \end{equation*}
    分别考察 $ x $ 在区间 $ (x_1, x_2) $ 的端点及内外时狄利克雷积分的值即可得
    \begin{equation*}
        \lim_{t \to +\infty} g (T, x, x_1, x_2) =
        \begin{cases}
            0, & x < x_1 \ \text{或} \ x > x_2,\\
            \dfrac{1}{2}, & x = x_1 \ \text{或} \ x = x_2,\\
            1, & x_1 < x < x_2,
        \end{cases}
    \end{equation*}
    且 $ \lvert g (T, x, x_1, x_2) \rvert $ 有界, 从而可以把积分号和极限号互换, 故有
    \begin{align*}
        \lim_{T \to +\infty} J_T & = \int_{-\infty}^{+\infty} \lim_{T \to +\infty} g (T, x, x_1, x_2) p (x) \dd x\\
        & = \int_{x_1}^{x_2} p (x) \dd x = F (x_2) - F (x_1).
    \end{align*}
    定理得证.
\end{proof}

\begin{theorem}{唯一性定理}{4.1.4}
    随机变量的分布函数由其特征函数唯一决定.
\end{theorem}

\begin{proof}
    对 $ F (x) $ 的每一个连续点 $ x $, 当 $ y $ 沿着 $ F (x) $ 的连续点趋于 $ -\infty $ 时, 由逆转公式得
    \begin{equation*}
        F (x) = \lim_{y \to -\infty} \lim_{T \to +\infty} \frac{1}{2\pi} \int_{-T}^T \frac{\ee^{-ity} - \ee^{-itx}}{it} \varphi (t) \dd t,
    \end{equation*}
    而分布函数由其连续点上的值惟一决定, 故结论成立.
\end{proof}

由于分布函数 $ F (x) $ 是非降函数， 因此我们一定能做到让 $ y $ 沿着 $ F (x) $ 的连续点趋于 $ -\infty $, 并且 $ F (x) $ 由其连续点上的值唯一确定, 而这些性质的证明在此从略了.

特别, 当 $ X $ 为连续随机变量, 有下述更强的结果.
\begin{theorem}{}{4.1.5}
    若 $ X $ 为连续随机变量, 其密度函数为 $ p (x) $, 特征函数为 $ \varphi (t) $.
    如果 $ \int_{-\infty}^{+\infty} \lvert \varphi (t) \rvert \dd t < +\infty $, 则
    \begin{equation}\label{eq:4.1.12}
        p (x) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-itx} \varphi (t) \dd t.
    \end{equation}
\end{theorem}

\begin{proof}
    记 $ X $ 的分布函数为 $ F (x) $, 由逆转公式知
    \begin{align*}
        p (x) & = \lim_{\Delta x \to 0} \frac{F (x + \Delta x) - F (x)}{\Delta x}\\
        & = \lim_{\Delta x \to 0} \frac{1}{2\pi} \int_{-\infty}^{+\infty} \frac{\ee^{-itx} - \ee^{-it (x + \Delta x)}}{it \cdot \Delta x} \varphi (t) \dd t.
    \end{align*}
    再次利用不等式 $ \lvert \ee^{ia} - 1 \rvert \leq \lvert a \rvert $, 就有
    \begin{equation*}
        \left\lvert \frac{\ee^{-itx} - \ee^{-it (x + \Delta x)}}{it \cdot \Delta x} \right\rvert \leq 1.
    \end{equation*}
    又因为 $ \int_{-\infty}^{+\infty} \lvert \varphi (t) \rvert < +\infty $, 所以可以交换极限号和积分号, 即
    \begin{align*}
        p (x) & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \lim_{\Delta x \to 0} \frac{\ee^{-itx} - \ee^{-it (x + \Delta x)}}{it \cdot \Delta x} \varphi (t) \dd t\\
        & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-itx} \varphi (t) \dd t.
    \end{align*}
    定理得证.
\end{proof}

\eqref{eq:4.1.12} 在数学分析中也称为傅里叶逆变换, 所以 \eqref{eq:4.1.3} 和 \eqref{eq:4.1.12} 实质上是一对互逆的变换:
\begin{gather*}
    \varphi (t) = \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x,\\
    P (x) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-itx} \varphi (t) \dd t.
\end{gather*}
即特征函数是密度函数的傅里叶变换, 而密度函数是特征函数的傅星叶逆变换

在此着重指出: 在概率论中, 独立随机变量和的问题占有``中心''地位, 用卷积公式去处理独立随机变量和的问题是相当复杂, 而引入了特征函数可以很方便地用特征函数相乘求得独立随机变量和的特征函数, 由此大大简化了处理独立随机变量和的难度.
读者可从下例中体会出这一点.

\begin{example}\label{exam:4.1.4}
    在 3.3.4 节中, 我们用卷积公式通过复杂的计算证明了二项分布、泊松分布、伽玛分布和 $ \chi^2 $ 分布的可加性.
    现在用特征函数方法 (性质~\ref{prop:4.1.4} 和唯一性定理) 可以很方便地证明正态分布的可加性.
    设 $ X \sim N ( \mu_1, \sigma_1^2) $, $ Y \sim N ( \mu_2, \sigma_2^2) $ 且 $ X $ 与 $ Y $ 独立.
    因为
    \begin{equation*}
        \varphi_X (t) = \exp \left( it\mu_1 - \frac{\sigma_1^2 t^2}{2} \right), \ \varphi_Y (t) = \exp \left( it\mu_2 - \frac{\sigma_2^2 t^2}{2} \right)
    \end{equation*}
    所以由性质~\ref{prop:4.1.4} 得
    \begin{equation*}
        \varphi_{X+Y} (t) = \varphi_X (t) \cdot \varphi_Y (t) = \exp \left( it ( \mu_1 + \mu_2 ) - \frac{(\sigma_1^2 + \sigma_2^2) t^2}{2} \right).
    \end{equation*}
    这正是 $ N ( \mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2 ) $ 的特征函数, 再由特征函数的唯一性定理, 即知
    \begin{equation*}
        X + Y \sim N ( \mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2 ).
    \end{equation*}
    同理可证: 若 $ X_j $ 相互独立, 且 $ X_j \sim N ( \mu_j, \sigma_j^2 ) $, $ j = 1,2,\dotsc,n $, 则
    \begin{equation*}
        \sum_{j=1}^n X_j \sim N \left( \sum_{j=1}^n \mu_j, \sum_{j=1}^n \sigma_J^2 \right).
    \end{equation*}
\end{example}

\begin{example}
    已知连续随机变量的特征函数如下, 求其分布.
    \begin{enumerate}
        \item $ \varphi_1 (t) = \ee^{- \lvert t \rvert} $,
        \item $ \varphi_2 (t) = \frac{\sim at}{at} $.
    \end{enumerate}
\end{example}

\begin{solution}
    \begin{enumerate}
        \item 由逆转公式 \eqref{eq:4.1.12} 可知其密度函数为
        \begin{align*}
            p (x) & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-ixt} \cdot \ee^{- \lvert t \rvert} \dd t\\
            & = \frac{1}{2\pi} \int_{0}^{+\infty} \ee^{- (1 + ix)t} \dd t + \frac{1}{2\pi} \int_{-\infty}^{0} \ee^{(1 - ix)t} \dd t\\
            & = \frac{1}{2\pi} \left( \frac{1}{1 + ix} + \frac{1}{1 - ix} \right) = \frac{1}{\pi ( 1 + x^2 )}
        \end{align*}
        这是柯西分布, 所以特征函数 $ \varphi_1 (t) = e^{-\lvert t \rvert} $ 对应的是柯西分布.
        \item $ \varphi_2 (t) = \sin at / at $ 是均匀分布 $ U ( -a, a ) $ 的特征函数, 由唯一性定理知, 该特征函数对应的分布不是别的, 只能是均匀分布 $ U ( -a, a ) $.
    \end{enumerate}
\end{solution}

\begin{xiti}
    \item 设离微随机变量 $ X $ 的分布列如下, 试求 $ X $ 的特征函数.
    
    \begin{tabularx}{0.95\linewidth}{>{\centering\arraybackslash}X|*{5}{>{\centering\arraybackslash}X}}
        \toprule
        $X$ & 0 & 1 & 2 & 3\\
        \midrule
        $P$ & 0.4 & 0.3 & 0.2 & 0.1\\
        \bottomrule
    \end{tabularx}
    \item 设离散随机变量 $ X $ 服从几何分布
    \begin{equation*}
        P ( X = k ) = ( 1 - p )^{k - 1} p, \ k=1,2,\dotsc.
    \end{equation*}
    试求 $ X $ 的特征函数, 并以此求 $ E ( X ) $ 和 $ Var ( X ) $.
    \item 设离散随机变量 $ X $ 服从巴斯卡分布
    \begin{equation*}
        P ( X = k ) = \binom{k - 1}{r - 1} p^r ( 1 - p )^{k - r}, \ k=r, r+1, \dotsc.
    \end{equation*}
    试求 $ X $ 的特征函数.
    \item 求下列分布函数的特征函数, 并由特征函数求其数学期望和方差.
    \begin{enumerate}
        \item $ F_1 (x) = a/2 \int_{-\infty}^x \ee^{-a \lvert x \rvert} \dd x, \ ( a > 0 ) $.
        \item $ F_2 (x) = a/\pi \int_{-\infty}^x \frac{1}{x^2 + a^2} \dd x, \ ( a > 0 ) $.
    \end{enumerate}
    \item 设 $ X \sim N ( \mu, \sigma^2 ) $, 试用特征函数的方法求 $ X $ 的3阶及4阶中心矩.
    \item 试用特征函数的方法证明二项分布的可加性: 若 $ X \sim b ( m, p ) $, $ Y \sim b ( m, p ) $, 且 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim b ( n + m, p ) $.
    \item 试用特征函数的方法证明泊松分布的可加性: 若 $ X \sim P ( \lambda_1 ) $, $ Y \sim P ( \lambda_2 ) $, 目 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim P ( \lambda_1 + \lambda_2 ) $.
    \item 试用特征函数的方法证明伽玛分布的可加性: 若 $ X \sim Ga ( a_1, \lambda ) $, $ Y \sim Ga ( a_1, \lambda ) $, 且 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim Ga ( a_1 + a_2, \lambda ) $.
    \item 试用特征函数的方法证明 $ \chi^2 $ 分布的可加性: 若 $ X \sim \chi^2 ( n ) $, $ Y \sim \chi^2 ( m ) $, 且 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim \chi^2 ( m + n ) $.
    \item 设 $ X_i $ 独立同分布, 且 $ X_i \sim Exp ( \lambda ) $, $ i = 1,2,\dotsc,n $. 试用特征函敷的方法证明: $ Y_n = \sum_{i=1}^n X_i \sim Ga ( n, \lambda ) $.
    \item 设连续随机变量 $ X $ 的密度函数如下:
    \begin{equation*}
        p (x) = \frac{1}{\pi} \cdot \frac{\lambda}{\lambda^2 + ( x - \mu )^2}, \ -\infty < x < +\infty.
    \end{equation*}
    其中参数 $ \lambda > 0 $, $ -\infty < \mu < +\infty $. 试证
    \begin{enumerate}
        \item $ X $ 的特征函数为 $ \exp \bigl( i\mu t - \lambda \lvert t \rvert \bigr) $, 且利用此结果证明柯西分布的可加性.
        \item 当 $ \mu = 0 $, $ \lambda = 1 $ 时, 记 $ Y = X $, 试证 $ \varphi_{X + Y} (t) = \varphi_X (t) \cdot \varphi_Y (t) $, 但是 $ X $ 与 $ Y $ 不独立.
        \item 若 $ X_1, X_2, \dotsc, X_n $ 相互独立, 且服从同一柯西分布, 试证: $ (1/n) ( X_1 + X_2 + \dotsb + X_n ) $ 与 $ X_1 $ 同分布.
    \end{enumerate}
    \item 设连续随机变量 $ X $ 的密度函数为 $ p (x) $, 试证: $ p (x) $ 关于原点对称的充要条件是它的特征函数是实的偶函数.
    \item 设 $ X_1, X_2, \dotsc, X_n $ 独立同分布, 且都服从 $ N (\mu, \sigma^2) $ 分布, 试求 $ \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i $ 的分布.
\end{xiti}

\section{大数定律}

``概率是频率的稳定值'', 其中``稳定''一词是什么含义?
在第一章我们从直观上描述稳定性: 频率在其概率附近摆动.
但如何摆动仍没说清楚, 现在可用大数定律来彻底说清这个问题了.

大数定律有多种形式, 下面从最简单的伯努利大数定律说起, 逐步介绍各种大数定律.

\subsection{伯努利大数定律}

记 $ \mu_n $ 为 $ n $ 重伯努利试验中事件 $ A $ 出现的次数, 称 $ \mu_n / n $ 为事件 $ A $ 出现的频率.

如果记一次试验中 $ A $ 发生的概率为 $ p $, 则 $ \mu_n $ 服从二项分布 $ b (n, p $, 因此频率 $ \mu_n / n $ 的数学期望与方差分别为
\begin{equation}\label{eq:4.2.1}
    E \left( \frac{\mu_n}{n} \right) = p, \ Var \left( \frac{\mu_n}{n} \right) = \frac{p ( 1 - p )}{n}.
\end{equation}

下面我们讨论 $ n \to +\infty $ 时, 频率 $ \mu_n / n $ 的极限状态.

由 \eqref{eq:4.2.1} 式, 当 $ n \to +\infty $  时, 频率的数学期望 $ p $ 保持不变, 而方差趋于0.
我们已经知道方差为0的随机变量是常数, 那么现在的问题是频率 $ \mu_n / n $ 是如何``收敛于''概率 $ p $, 即我们如何来理解``收敛''一词.

按数学分析中的数列极限概念, 数列 $ \{ \mu_n / n \} $ 的极限为 $ p $,
\begin{equation*}
    \lim_{n \to +\infty} \frac{\mu_n}{n} = p,
\end{equation*}
即对任意的 $ \varepsilon > 0 $, 当 $ n $ 充分大时, ``必定''有
\begin{equation*}
    \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon,
\end{equation*}
而其对立事件
\begin{equation*}
    \left\lvert \frac{\mu_n}{n} - p \right\rvert \geq \varepsilon,
\end{equation*}
是``必定''不会发生的.
然而在随机现象中各种情况都可能出现, 甚至事件``$ \mu_n = n $''也是可能发生的, 因为 $ p ( \mu_n = n )=p^n > 0 $, 即事件``$ \mu_n = n $''的概率大于零, 从而事件
\begin{equation*}
    \left\lvert \frac{\mu_n}{n} - p \right\rvert \geq \varepsilon,
\end{equation*}
就有可能发生.
这说明用数学分析中的极限来描述频率的极限是不妥当的, 是对频率随机性的认识不足的表现.

为此, 频率``收敛于''概率用以下方式描述是合适的: 当 $ n $ 充分大时, 频率 $ \mu_n / n $ 与概率 $ p $间有大偏差的概率很小, 而且随着 $ n $ 的增大, 它愈来愈小.
用数学语言来讲, 就是对任意的 $ \varepsilon > 0 $, 有
\begin{equation}\label{eq:4.2.2}
    \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) = 1.
\end{equation}
或
\begin{equation}\label{eq:4.2.3}
    \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert \geq \varepsilon \right) = 0.
\end{equation}
这种收敛性就称作\textbf{依概率收敛}\index{依概率收敛}, 它的一般定义将在 \S 4.3 节中给出.
下面的伯努利大数定律就是对上述讨论作了一个很好的总结.
\begin{theorem}{伯努利大数定律}{4.2.1}
    设 $ \mu_n $ 为 $ n $ 重伯努利试验中事件 A 发生的次数, $ p $为每次试验中 A 出现的概率, 则对任意的 $ \varepsilon > 0 $, 有
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) = 1.
    \end{equation*}
\end{theorem}

\begin{proof}
    因为 $ \mu_n \sim b ( n, p ) $, 且 $ \mu_n $ 的数学期望和方差如 \eqref{eq:4.2.1} 式所示.
    所以由切比雪夫不等式得
    \begin{equation}
        1 \geq P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) \geq 1 - \frac{Var (\mu_n / n)}{\varepsilon^2} = 1 - \frac{p ( 1 - p )}{n \varepsilon^2}.
    \end{equation}
    当 $ n \to + \infty $ 时, 上式右端趋于1, 因此
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) = 1.
    \end{equation*}
    结论得证.
\end{proof}

伯努利大数定律说明: 随着 $ n $的增大, 事件A发生的频率 $ \mu_n / n $ 与其频率 $ p $ 的偏差 $ \lvert \mu_n / n - p \rvert $ 大于预先给定的精度 $ \varepsilon $ 的可能性愈来愈小, 小到可以忽略不计.
这就是频率稳定于概率的含义, 或者说频率依概率收敛于概率.

譬如, 抛一枚硬币出现正面的概率 $ p = 0.5 $.
若把这枚硬币连抛10次, 则因为 $ n $ 较小, 发生大偏差的可能性有时会大一些, 有时会小一些.
若把这枚硬币连抛 $ n $,当 $ n $ 很大时, 由切比雪夫不等式知: 正面出现的频率与0.5的偏差大于预先给定的精度 $ \varepsilon $ (若取精度 $ \varepsilon = 0.01 $) 的可能性
\begin{equation*}
    P \left( \left\lvert \frac{\mu_n}{n} - 0.5 \right\vert > 0.01 \right) \leq \frac{0.5 \times 0.5}{n 0.01^n} = \frac{10^4}{4n}.
\end{equation*}
当 $ n = 10^5 $ 时, 大偏差发生的可能性小于 $ 1/40 = \SI{2.5}{\percent} $.
当 $ n = 10^6 $ 时, 大偏差发生的可能性小于 $ 1/400 = \SI{0.25}{\percent} $.
可见试验次数愈多，偏差发生的可能性愈小.

伯努利大数定律提供了用频率来确定概率的理论依据.
譬如要估计某种产品的不合格品率 $ p $, 则可从该种产品中随机抽取 $ n $ 件, 当 $ n $ 很大时, 这 $ n $ 件产品中的不合格品的比例可作为不合格品率 $ p $ 的估计值.

\begin{example}[(用蒙特卡洛方法计算定积分 (随机投点法))]\label{exam:4.2.1}
    设 $ 0 \leq f (x) \leq 1 $, 求 $ f (x) $ 在区间 $ [0, 1] $ 上的积分值:
    \begin{equation*}
        J = \int_0^1 f (x) \dd x.
    \end{equation*}
    设 $ (X,Y) $ 服从正方形 $ \{ 0 \leq x \leq 1, 0 \leq y \leq 1 \} $ 上的均匀分布, 则可知 $ X $ 服从 $ [ 0, 1 ] $ 上的均匀分布, $ Y $ 也服从 $ [ 0, 1 ] $ 上的均匀分布, 且 $ X $ 与 $ Y $ 独立.
    又记事件
    \begin{equation*}
        A = \{ Y \leq f (X) \},
    \end{equation*}
    则 $ A $ 的概率为
    \begin{equation*}
        p = P ( Y \leq f (x) ) = \int_0^1 \int_0^{f(x)} \dd y \dd x = \int_0^1 f (x) \dd x = J.
    \end{equation*}
    即定积分的值 $ J $ 就是事件 $ A $ 的概率 $ p $.
    由伯努利大数定律, 我们可以用重复试验中 $ A $ 出现的额率作为 $ p $ 的估计值.
    这种求定积分的方法也称为随机投点法, 即将 $ (X, Y) $ 看成是向正方形 $ \{ 0 \leq x \leq 1, 0 \leq y \leq 1 \} $ 内的随机投点, 用随机点落在区域 $ \{ y \leq f (x) \} $ 中的频率作为定积分的近似值.
    下面用蒙特卡洛方法, 来得到 $ A $ 出现的频率:
    \begin{enumerate}
        \item 先用计算机产生 $ (0, 1) $ 上均匀分布的 $ 2n $个随机数: $ x_i, y_i $, $ i=1, 2, \dotsc, n$, 这里 $ n $ 可以很大, 臂如 $ n = 10^4 $, 甚至 $ n = 10^5 $.
        \item 对 $ n $ 对数据 $ (x_i, y_i) $, $ i=1, 2, \dotsc, n $, 记录满足如下不等式
        \begin{equation*}
            y_i \leq f (x)
        \end{equation*}
        的次数, 这就是事件A发生的频数 $ \mu_n $.
        由此可得事件 $ A $发生的频率 $ \mu_n / n $, 则 $ J \approx \mu_n / n $.
    \end{enumerate}

    譬如计算 $ \int_0^1 \ee^{-x^2/2}/\sqrt{2\pi} \dd x $, ，其精确值和 $ n = 10^4 $, $ n = 10^5 $ 时的模拟值如下

    \begin{tabularx}{0.9\linewidth}{*{3}{>{\centering\arraybackslash}X}}
        \toprule
        精确值 & $ n = 10^4 $ & $ n = 10^5 $ \\
        \midrule
        \num{0.341344} & \num{0.340698} & \num{0.341355}\\
        \bottomrule
    \end{tabularx}

    注意，对于一般区间 $ [a, b] $ 上的定积分
    \begin{equation*}
        J' = \int_a^b g (x) \dd x,
    \end{equation*}
    作线性变换 $ y=(x-a)/(b-a) $, 即可化成 $ [0, 1] $ 区间上的积分.
    进一步若 $ c \leq g(x) \leq d$, 可令
    \begin{equation*}
        f (y) = \frac{1}{d-c} \bigl( g ( a + ( b - a ) y ) - c \bigr),
    \end{equation*}
    则 $ 0 \leq f (y) \leq 1 $.
    此时有
    \begin{equation*}
        J' = \int_a^b g (x) \dd x = S_0 \int_0^1 f (y) \dd y + c ( b - a ).
    \end{equation*}
    其中 $ S_0 = ( b -a ) ( d - c ) $.
    这说明以上用蒙特卡洛方法计算定积分方法带有普遍意义.
\end{example}

\subsection{常用的几个大数定律}

\subsubsection{大数定律的一般形式}

伯努利大数定律讨论的是一个相互独立同分布的随机变量序列 $ \{ X_n \} $, 其共同分布为二点分布.
若记
\begin{equation*}
    X_i =
    \begin{cases}
        1, & \text{第} \ i \ \text{次试验中事件} \ A \ \text{发生},\\
        0, & \text{第} \ i \ \text{次试验中事件} \ A \ \text{不发生},
    \end{cases}
    \quad i=1,2,\dotsc,n,\dotsc,
\end{equation*}
则 $ \{ X_n \} $ 是独立的二点分布随机变量序列, 现考察该序列的前 $ n $ 个随机变量之和 $ \mu_n = \sum_{i=1}^n X_i $, 其频率及频率的数学期望分别为
\begin{equation*}
    \frac{\mu_n}{n} \frac{1}{n} \sum_{i=1}^n X_i, \quad p = E \left( \frac{1}{n} \sum_{i=1}^n X_i \right) = \frac{1}{n} \sum_{i=1}^n E (X_i).
\end{equation*}
那么伯努利大数定律的结论为: 对任意的 $ \varepsilon > 0 $, 有
\begin{equation}\label{eq:4.2.5}
    \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n X_i - \frac{1}{n} \sum_{i=1}^n E (X_i) \right\rvert < \varepsilon \right) = 1.
\end{equation}
一般的大数定律都涉及一个随机变量序列 $ \{ X_n \} $, 大数定律的结论都是形如 \eqref{eq:4.2.5}, 为此我们给出如下定义.

\begin{definition}{}{4.2.1}
    设有一随机变量序列 $ \{ X_n \} $, 假如它具有形如 \eqref{eq:4.2.5} 的性质, 则称该随机变量序列 $ \{ X_n \} $ 服从\textbf{大数定律}\index{大数定律}.
\end{definition}

不同的大数定律的差别只是对不同的随机变量序列 $ \{ X_n \} $ 而言, 有的是相互独立的随机变量序列, 有的是相依的随机变量序列, 有的是同分布的随机变量序列, 有的是不同分布的随机变量序列等等.

\subsubsection{切比需夫大数定律}

利用切比雪夫不等式就可证明下面的切比雪夫大数定律.

\begin{theorem}{切比需夫大数定律}{4.2.2}
    设 $ \{ X_n \} $ 为一列两两不相关的随机变量序列, 若每个 $ X_i $ 的方差存在, 且有共同的上界, 即 $ Var (X) \le c $, $ i=1,2, \dotsc $, 则 $ \{ X_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $,  \eqref{eq:4.2.5}  成立.
\end{theorem}

\begin{proof}
    因为 $ \{ X_n \} $ 两两不相关, 故
    \begin{equation*}
        Var \left( \frac{1}{n} \sum_{i=1}^n X_i \right) = \frac{1}{n^2} \sum_{i=1}^n Var \bigl( X_i \bigr) \leq \frac{c}{n}.
    \end{equation*}
    再由切比雪夫不等式得到: 对任意的 $ \varepsilon > 0 $, 有
    \begin{equation*}
        P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n X_i - \frac{1}{n} \sum_{i=1}^n E \bigl( X_i \bigr) \right\rvert < \varepsilon \right) \geq 1 - \frac{Var\left( \frac{1}{n} \sum_{i=1}^n X_i \right)}{\varepsilon^2} \geq 1 - \frac{c}{n\varepsilon^2}.
    \end{equation*}
    于是当 $ n \to +\infty $ 时, 有
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n X_i - \frac{1}{n} \sum_{i=1}^n E \bigl( X_i \bigr) \right\rvert < \varepsilon \right) = 1.
    \end{equation*}
\end{proof}

注意, 切比雪夫大数定律只要求 $ \{ X_n \} $ 互不相关, 并不要求它们是同分布的.
假如 $ \{ X_n \} $ 是独立同分布的随机变量序列, 且方差有限, 则 $ \{ X_n \} $ 必定服从大数定律.

\begin{example}\label{exam:4.2.2}
    设 $ \{ X_n \} $ 是独立同分布的随机变量序列, $ E \bigl( X_n^4 \bigr) < +\infty $. 若令 $ E \bigl( X_n^4 \bigr) < +\infty $, $ Var \bigl( X_n \bigr)= \sigma^2 $, 考察
    \begin{equation*}
        Y_n = \bigl( X_n - \mu \bigr)^2, \quad n = 1, 2, \dotsc,
    \end{equation*}
    则随机变量序列 $ \{ Y_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $, 有
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n \bigl( X_i - \mu \bigr)^2 - \sigma^2 \right\rvert \geq \varepsilon \right) = 0.
    \end{equation*}
\end{example}

\begin{proof}
    显然 $ \{ Y_n \} $ 是独立同分布随机变量序列, 其方差
    \begin{equation*}
        Var \bigl( Y_n \bigr) = Var \bigl( X_n - \mu \bigr)^2 = E \bigl( X_n - \mu \bigr)^4 - \sigma^4.
    \end{equation*}
    由于 $ E \bigl( X_n^4 \bigr) $ 存在, 故 $ E \bigl( X_n^3 \bigr) $ ,  $ E \bigl( X_n^2 \bigr) $ 皆存在, 从而 $ E \bigl( X_n - \mu \bigr)^4 $ 也存在.
    由切比雪夫大数定律知
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n Y_i - \frac{1}{n} \sum_{i=1}^n E \bigl( Y_i \bigr) \right\rvert \geq \varepsilon \right) = 0.
    \end{equation*}
    其中
    \begin{equation*}
        \frac{1}{n} \sum_{i=1}^n Y_n = \frac{1}{n} \sum_{i=1}^n \bigl( X_i - \mu \bigr)^2, \ \frac{1}{n} \sum_{i=1}^n E \bigl( Y_n \bigr) = \sigma^2.
    \end{equation*}
    故 $ \{ Y_n \} $ 服从大数定律.
\end{proof}

\subsubsection{马尔可夫大数定律}

注意到以上大数定律的证明中, 只要有
\begin{equation*}\label{eq:4.2.6}
    \frac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) \to 0.
\end{equation*}
则大数定律就能成立.
这个条件 \ref{eq:4.2.6} 被称为\textbf{马尔可夫条件}\index{马尔可夫条件}.

\begin{theorem}{马尔可夫大数定律}{4.2.3}
    对随机变量序列 $ \{ X_n \} $, 若 \ref{eq:4.2.6} 成立, 则 $ \{ X_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $, \eqref{eq:4.2.5} 成立.
\end{theorem}

\begin{proof}
    利用切比雪夫不等式即可证得.
\end{proof}

马尔可夫大数定律的重要性在于: 对 $ \{ X_n \} $ 已经没有任何同分布、独立性、不相关的假定.
切比雪夫大数定律显然可由马尔可夫大数定律推出.

\begin{example}\label{exam:4.2.3}
    设 $ \{ X_n \} $ 为一同分布、方差存在的随机变量序列, 且 $ X_n $ 仅与 $ X_{n-1} $ 和 $ X_{n+1} $ 相关, 而与其他的 $ X_i $ 不相关.
    试问该随机变量序列 $ \{ X_n \} $ 是否服从大数定律？
\end{example}

\begin{proof}
    $ \{ X_n \} $ 为相依随机变量序列, 考虑其马尔可夫条件
    \begin{equation*}
        \frac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) = \frac{1}{n^2} \left( \sum_{i=1}^n Var \bigl( X_i \bigr) + 2 \sum_{i=1}^{n-1} Cov \bigl( X_i, X_{i-1} \bigr) \right)
    \end{equation*}
    记 $ Var ( X_i ) = \sigma^2 $, 则 $ \lvert Cov ( X_i, X_j ) \rvert \leq \sigma^2 $, 于是有
    \begin{equation*}
        \frac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) \leq \frac{1}{n^2} \bigl( n \sigma^2 + 2 ( n - 1 ) \sigma^2 \bigr) \to 0, \ ( n \to +\infty ),
    \end{equation*}
    即马尔可夫条件成立, 故 $ \{ X_n \} $ 服从大数定律.
\end{proof}

\subsubsection{辛钦大数定律}

我们已经知道, 一个随机变量的方差存在, 则其数学期望必定存在; 但反之不成立, 即一个随机变量的数学期望存在, 则其方差不一定存在.
以上几个大数定律均假设随机变量序列 $ \{ X_n \} $ 的方差存在, 以下的辛钦大数定律去掉了这一假设, 仅设每个 $ X_i $ 的数学期望存在, 但同时要求 $ \{ X_n \} $ 为独立同分布的随机变量序列.
伯努利大数定律仍然是辛钦大数定律的特例.

\begin{theorem}{辛钦大数定律}{4.2.4}
    设 $ \{ X_n \} $ 为一独立同分布的随机变量序列, 若 $ X_i $ 的数学期望存在, 则 $ \{ X_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $, \eqref{eq:4.2.5} 成立.
\end{theorem}

这个定理的证明要用到特征函数这一工具, 在下一节中给出具体证明.

辛钦大数定律提供了求随机变量数学期望 $ E ( X ) $ 的近似值的方法.
设想对随机变量 $ X $ 独立重复地观察 $ n $ 次, 第 $ k $ 次观察值为 $ X_k $, 则 $ X1,X2, \dotsc, X_n $ 应该是相互独立的, 且它们的分布应该与 $ X $ 的分布相同.
所以, 在 $ E (X) $ 存在的条件下, 按照辛钦大数定律, 当 $ n $ 足够大时, 可以把平均观察值
\begin{equation*}
    \frac{1}{n} \sum_{i=1}^n X_i
\end{equation*}
作为 $ E ( X ) $ 的近似值.
这样做法的一个优点是我们可以不必去管 $ X $ 的分布究竟是怎样的, 我们的目的只是寻求数学期望.

事实上, 用观察值的平均去作为随机变量的均值在实际生活中是常用的方法.
管如, 用观察到的某地区 \num{5000} 个人的平均寿命作为该地区的人均寿命的近似值是合适的, 这样做法的依据就是辛钦大数定律.

\begin{example}[(用蒙特卡洛方法计算定积分 (平均值法))]\label{exam:4.2.4}
    为计算定积分
    \begin{equation*}
        J = \int_0^1 f (x) \dd x.
    \end{equation*}
    设随机变量 $ X $ 服从 $ ( 0, 1 ) $ 上的均匀分布, 则 $ Y = f (X) $ 的数学期望为
    \begin{equation*}
        E \bigl( f (X) \bigr) = \int_0^1 f (x) \dd x = J.
    \end{equation*}
    所以估计 $ J $ 的值就是估计 $ f (X) $ 的数学期望的值.
    由辛钦大数定律， 可以用 $ f (X) $ 的观察值的平均去估计 $ f (X) $ 的数学期望的值.
    具体做法如下: 先用计算机产生 $ n $ 个 $ (0, 1) $ 上均匀分布的随机数: $ x_i $, $ i = 1, 2, \dotsc, n $. 然后对每个 $ x_i $ 计算 $ f (x_i) $, 最后得 $ J $ 的估计值为
    \begin{equation*}
        J \approx \frac{1}{n} \sum_{i=1}^n f (x_i).
    \end{equation*}

    譬如计算 $ \int_0^1 \ee^{-x^2/2} / \sqrt{2\pi} \dd x $, 其精确值和 $ n = 10^4 $, $ n = 10^5 $ 时的模拟值如下:

    \begin{tabularx}{0.9\linewidth}{*{3}{>{\centering\arraybackslash}X}}
        \toprule
        精确值 & $ n = 10^4 $ & $ n = 10^5 $ \\
        \midrule
        \num{0.341344} & \num{0.341329} & \num{0.341334}\\
        \bottomrule
    \end{tabularx}
    
    正如例~\ref{exam:4.2.1} 中所说明的, 可以通过线性变换将 $ [a, b] $ 区间上的定积分化成 $ [O, 1] $ 区间上的定积分, 所以以上方法计算定积分方法带有普遍意义。
\end{example}

\begin{xiti}
    \item 设 $ \{ X_k \} $ 为独立随机变量序列, 且
    \begin{equation*}
        P \bigl( X_k = \pm \sqrt{\ln k} \bigr) = \frac{1}{2}, \ k = 1, 2, \dotsc.
    \end{equation*}
    证明 $ \{ X_k \} $ 服从大数定律.
    \item 设 $ \{ X_k \} $ 为独立随机变量序列, 且
    \begin{equation*}
        P \bigl( X_k = \pm 2^k \bigr) = \frac{1}{2^{2k+1}}, \ P \bigl( X_k = 0 \bigr) = 1 - \frac{1}{2^{2k}}, \ k = 1, 2, \dotsc .
    \end{equation*}
    证明 $ \{ X_k \} $ 服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立随机变量序列, 且 $ P \bigl( X_1 = 0 \bigr) = 1 $,
    \begin{equation*}
        P \bigl( X_n = \pm \sqrt{n} \bigr) = \frac{1}{n}, \ P \bigl( X_n = 0 \bigr) = 1 - \frac{2}{n}, \ n = 2, 3, \dotsc .
    \end{equation*}
    证明 $ \{ X_n \} $ 服从大数定律.
    \item 在伯努利试验中, 事件 $ A $ 出现的概率为 $ p $, 令
    \begin{equation*}
        X+n = 
        \begin{cases}
            1, & \text{若在第} \ n \ \text{次及第} \ n+1 \ \text{次试验中} \ A \ \text{出现}\\
            0, & \text{其他}.
        \end{cases}
    \end{equation*}
    证明 $ \{ X_n \} $ 服从大数定律.
    \item  设 $ \{ X_n \} $ 为独立的随机变量序列, 且
    \begin{equation*}
        P \bigl( X_n = 1 \bigr) = p_n, \ P \bigl( X_n = 0 \bigr) = 1 - p_n.
    \end{equation*}
    证明 $ \{ X_n \} $ 服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其共同的分布函数为
    \begin{equation*}
        F (x) = \frac{1}{2} + \frac{1}{\pi} \arctan \frac{a}{x}, \ -\infty < x < +\infty 
    \end{equation*}
    试问: 辛钦大数定律对此随机变量序列是否适用?
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其共同分布为
    \begin{equation*}
        P \left( X_n = \frac{2^k}{k^2} \right) = \frac{1}{2^k}, \ k = 1, 2, \dotsc .
    \end{equation*}
    试问 $ \{ X_n \} $ 是否服从大数定律?
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其共同分布为
    \begin{equation*}
        P \bigl( X_n = k \bigr) = \frac{c}{k^2 \cdot \log^2 k}, \ k = 2, 3, \dotsc .
    \end{equation*}
    其中
    \begin{equation*}
        c = \left( \sum_{k = 2}^{+\infty} \frac{1}{k^2 \cdot \log^2 k} \right)^{-1},
    \end{equation*}
    试同 $ \{ X_n \} $ 是否服从大数定律?
    \item 设 $ \{ X_n \} $ 为独立的随机变量序列, 其中 $ X_n $ 服从参数为 $ \sqrt{n} $ 的泊松分布, 试问 $ \{ X_n \} $ 是否服从大数定律?
    \item 设 $ \{ X_n \} $ 为独立的随机变量序列, 每个 $ X_n $ 的方差 $ \sigma^2 $ 有限, 证明: 若
    \begin{equation*}
        \frac{\sigma_n^2}{n} \to 0, \ n \to +\infty.
    \end{equation*}
    则 $ \{ X_n \} $ 服从大数定律.
    \item (伯恩斯组大数定律) 设 $ \{ X_n \} $ 是方差有界的随机变量序列, 且当 $ \lvert k - l \rvert \to +\infty $ 时, 一致地有 $ Cov \bigl( X_k, X_l \bigr) \to 0 $, 证明 $ \{ X_n \} $ 服从大数定律.
    \item (格涅坚科大数定律) 设 $ \{ X_n \} $ 是随机变量序列, 若记
    \begin{equation*}
        Y_n = \frac{1}{n} \sum_{i=1}^n X_i, \ a_n = \frac{1}{n} \sum_{i=1}^n E (x_i).
    \end{equation*}
    则 $ \{ X_n \} $ 服从大数定律的充要条件是
    \begin{equation*}
        \lim_{n \to +\infty} E \left( \frac{( Y_n - a_n )^2}{1 + ( Y_n - a_n )^2} \right) = 0.
    \end{equation*}
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 方差存在.
    又设 $ \sum_{n=1}^{+\infty} a_n $ 为绝对收敛级数.
    令 $ Y = \sum_{i=1}^n X_i $, 证明 $ \{ a_n Y_n \} $服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 方差存在, 令 $ Y = \sum_{i=1}^n X_i $. 又设 $ \{ a_n \} $ 为一列常数, 如果存在常数 $ c > 0 $, 使得对一一切 $ n $ 有 $ \lvert n a_n \rvert \leq c $, 证明 $ \{ a_n Y_n \} $ 服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其方差有限, 且 $ X_n $ 不恒为常数.
    如果 $ S_n = \sum_{i=1}^n X_i $, 试证: 随机变量序列 $ \{ S_n \} $ 不服从大数定律.
    \item 分别用随机投点法和平均值法计算下列定积分:
    \begin{equation*}
        J_1 = \int_0^1 \frac{e^x - 1}{e - 1} \dd x, \ J_2 = \int_{-1}^1 \ee^x \dd x.
    \end{equation*}
\end{xiti}

\subsection{随机变量序列的两种收敛性}

随机变量序列的收敛性有多种, 其中常用的是两种: 依概率收敛和按分布收敛.
前面叙述的大数定律涉及的是一种依概率收敛, 后面叙述的中心极限定理将涉及按分布收敛.
这些极限定理不仅是概率论研究的中心议题, 而且在数理统计中有广泛的应用.
本节将给出这两种收敛性的定义及其有关性质, 读者应从中吸收其思考问题的方法.

\subsubsection{1依概率收敛}

首先由随机变量序列 $ \{ X_n \} $ 服从``大数定律''的讨论启发我们引进如下定义.

\begin{definition}{依概率收敛}{4.3.1}
    设 $ \{ Y_n \} $ 为一随机变量序列, $ Y $ 为一随机变量.
    如果对任意的 $ \varepsilon > c $, 有
    \begin{equation}\label{eq:4.3.1}
        \lim_{n \to +\infty} P \bigl( \bigr\lvert Y_n - Y \bigr\rvert < \varepsilon \bigr) = 1,
    \end{equation}
    则称 $ \{ Y_n \} $ \textbf{依概率收敛}\index{依概率收敛} 于 $ Y $, 记作 $ Y_n \stackrel{P}{\to} Y $.
\end{definition}

前面讨论的独立同分布随机变量序列 $ \{ X_n \} $ 服从大数定律是上述依概率收敛的特殊情况, 这只要构造另一个随机变量序列 $ \{ Y_n \} $, 其中