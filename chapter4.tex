% Edit by: Xiao Xing
% !TEX root = ./main.tex

\chapter{大数定律与中心极限定理}
大数定律与中心极限定理

\section{特征函数}

设 $ p (x) $ 是随机变量 $ X $ 的密度函数,
则 $ p (x) $ 的傅里叶变换是
\begin{equation*}
    \varphi (t) = \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x,
\end{equation*}
其中 $ i = \sqrt{-1} $ 是虚数单位.
由数学期望的概念知,
$ \varphi (t) $ 恰好是 $ E \bigl( \ee^{itx} \bigr) $.
这就是本节要讨论的特征函数,
它是处理许多概率论问题的有力工具,
它能把寻求独立随机变量和的分布的卷积运算 (积分运算) 转换成乘法运算,
还能把求分布的各阶原点矩 (积分运算) 转换成微分运算.
特别它能把寻求随机变量序列的极限分布转换成一般的函数极限问题,
下面从特征函数的定义开始介绍它们.

\subsection{特征函数的定义}

\begin{definition}{}{4.1.1}
    设 $ X $ 是一个随机变量,
    称
    \begin{equation}\label{eq:4.1.1}
        \varphi (t) = E \bigl( \ee^{itx} \bigr), \; -\infty \leq t \leq +\infty,
    \end{equation}
    为 $ X $ 的\textbf{特征函数}\index{特征函数}.
\end{definition}

因为 $ \lvert \ee^{itx} \rvert \leq 1 $,
所以 $ E \bigl( \ee^{itX} \bigr) $ 总是存在的,
即任一随机变量的特征函数总是存在的.

当离散随机变量 $ X $ 的分布列为 $ p_k = P ( X = x_k ) $, $ k = 1,2,\dotsc $,
则 $ X $ 的特征函数为
\begin{equation}\label{eq:4.1.2}
    \varphi (t) = \sum_{k=1}^{+\infty} \ee^{itx_k} p_k, \; -\infty \leq t \leq +\infty.
\end{equation}

当连续随机变量 $ X $ 的密度函数为 $ p (x) $,
则 $ X $ 的特征函数为
\begin{equation}\label{eq:4.1.3}
    \varphi (t) = \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x, \; -\infty \leq t \leq +\infty.
\end{equation}

与随机变量的数学期望、方差及各阶矩一样,
特征函数只依赖于随机变量的分布,
分布相同则特征函数也相同,
所以我们也常称为某\textbf{分布的特征函数}\index{特征函数!分布的特征函数}.


\begin{example}\label{exam:4.1.1}
    常用分布的特征函数
    \begin{enumerate}
        \item
        \textbf{单点分布}\index{分布!单点分布}: $ P (X = a) = 1 $, 
        其特征函数为
        \begin{equation*}
            \varphi (t) = \ee^{itz}.
        \end{equation*}
        \item\label{exam:4.1.1.2}
        \textbf{0-1分布}\index{分布!0-1分布}: $ P( X = x ) = p^x  ( 1 - p )^{1 - x} $, $ x = 0,1 $,
        其特征函数为
        \begin{equation*}
            \varphi (t) = p \ee^{it} + q, \quad \text{其中} \ q= 1 - p.
        \end{equation*}
        \item
        \textbf{泊松分布}\index{分布!泊松分布}: $ P ( X = k ) = ( \lambda^k/k! ) \ee^{-\lambda} $, $ k = 0, 1, \dotsc $, 其特征函数为
        \begin{equation*}
            \varphi (t) = \sum_{k=0}^{+\infty} \ee^{ikt} \frac{\lambda^k}{k!} \ee^{-\lambda} = \ee^{\lambda} \ee^{\lambda \ee^{it}} = \ee^{\lambda ( \ee^{it} ) -1}.
        \end{equation*}
        \item
        \textbf{均匀分布}\index{分布!均匀分布} $ U ( a,b ) $: 因为密度函数为
        \begin{equation*}
            p (x) = 
            \begin{cases}
                \dfrac{1}{b-a}, & a < x < b,\\
                0, & \text{其他}.
            \end{cases}
        \end{equation*}
        所以特征函数为
        \begin{equation*}
            \varphi (t) = \int_a^b \frac{\ee^{itx}}{b - a} \dd x = \frac{\ee^{ibt} - \ee^{iat}}{it (b-a)}.
        \end{equation*}
        \item
        \textbf{标准正态分布}\index{分布!标准正态分布} $ N (0,1) $: 因为密度函数为
        \begin{equation*}
            p (x) = \frac{1}{\sqrt{2\pi}} \exp \left( -\frac{x^2}{2} \right), \quad - \infty < x < + \infty.
        \end{equation*}
        所以特征函数为
        \begin{align*}
            \varphi (t) & = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} \exp \left( itx - \frac{x^2}{2} \right) \dd x\\
            & = \exp \left( -\frac{t^2}{2} \right) \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} \exp \left( -\frac{( x - it )^2}{2} \right) \dd x\\
            & = \exp \left( -\frac{t^2}{2} \right) \frac{1}{\sqrt{2\pi}} \int_{-\infty -it}^{+\infty -it} \exp \left( -\frac{x^2}{2} \right) \dd x\\
            & = \exp \left( -\frac{t^2}{2} \right),
        \end{align*}
        其中
        \begin{equation*}
            \int_{-\infty -it}^{+\infty -it} \exp \left( -\frac{x^2}{2} \right) \dd x = \sqrt{2\pi}
        \end{equation*}
        是利用复变函数中的围道积分求得的.
        有了标准正态分布的特征函数,
        再利用下节给出的特征函数的性质,
        就很容易得到一般正态分布 $ N ( \mu, \sigma^2 ) $ 的特征函数,
        见例~\ref{exam:4.1.2}.
        \item
        \textbf{指数分布}\index{分布!指数分布} $ Exp ( \lambda ) $: 因为密度函数为
        \begin{equation*}
            p (x) =
            \begin{cases}
                \lambda \ee^{-\lambda x}, & x > 0,\\
                0, & x \leq 0.
            \end{cases}
        \end{equation*}
        所以特征函数为
        \begin{align*}
            \varphi (t) & = \int_0^{+\infty} \ee^{itx} \lambda \ee^{-\lambda x} \dd x\\
            & = \lambda \left( \int_0^{+\infty} \cos (tx) \ee^{-\lambda x} \dd x + i \int_0^{+\infty} \sin (tx) \ee^{-\lambda x} \dd x \right)\\
            & = \lambda \left( \frac{\lambda}{\lambda^2 + t^2} + i \frac{t}{\lambda^2 + t^2} \right)\\
            & = \left( 1 - \frac{it}{\lambda} \right)^{-1}.
        \end{align*}
        以上积分中用到了复变函数中的欧拉公式: $ \ee^{itx} = \cos (tx) + i \sin ( tx) $.
    \end{enumerate}
\end{example}

\subsection{特征函数的性质}

现在我们来研究特征函数的一些性质,
其中 $ \varphi_X (t) $ 表示 $ X $ 的特征函数,
其他类似.

\begin{property}\label{prop:4.1.1}
    \begin{equation}\label{eq:4.1.4}
        \lvert \varphi (t) \rvert \leq \varphi (0) = 1.
    \end{equation}
\end{property}

\begin{property}\label{prop:4.1.2}
    \begin{equation}\label{eq:4.1.5}
        \varphi (-t) = \overline{\varphi (t)},
    \end{equation}
    其中 $ \overline{\varphi (t)} $ 表示 $ \varphi (t) $ 的共轭.
\end{property}

\begin{property}\label{prop:4.1.3}
    若 $ Y = aX + b $, 其中 $ a,b $ 是常数, 则
    \begin{equation}\label{eq:4.1.6}
        \varphi_Y (t) = \ee^{ibt} \varphi_X (at).
    \end{equation}
\end{property}

\begin{property}\label{prop:4.1.4}
    独立随机变量和的特征函数为特征函数的积,
    即设 $ X $ 与 $ Y $ 相互独立, 则
    \begin{equation}\label{eq:4.1.7}
        \varphi_{X+Y} (t) = \varphi_X (t) \cdot \varphi_Y (t).
    \end{equation}
\end{property}

\begin{property}\label{prop:4.1.5}
    若 $ E (x^l) $ 存在,
    则 $ X $ 的特征函数 $ \varphi(t) $ 可 $ l $ 次求导,
    且对 $ 1 \leq k \leq l $, 有
    \begin{equation}\label{eq:4.1.8}
        \varphi^{(k)} (0) = i^k E ( X^k ).
    \end{equation}
    上式提供了一条求随机变量的各阶矩的途径,
    特别可用下式去求数学期望和方差.
    \begin{equation}\label{eq:4.1.9}
        E (X) = \frac{\varphi' (0)}{i}, \quad \mathrm{Var} (X) = - \varphi'' (0) + \bigl( \varphi' (0) \bigr)^2.
    \end{equation}
\end{property}

\begin{proof}
    在此我们仅对连续场合进行证明,
    而在离散场合的证明是类似的.
    \begin{enumerate}
        \item 
        \begin{align*}
            \lvert \varphi (t) \rvert & = \left\lvert \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x \right\rvert 
            \leq \int_{-\infty}^{+\infty} \left\lvert \ee^{itx} \right\rvert p (x) \dd x\\
            & = \int_{-\infty}^{+\infty} p (x) \dd x
            = \varphi (0)
            = 1.
        \end{align*}
        \item 
        \begin{equation*}
            \varphi (-t) = \int_{-\infty}^{+\infty} \ee^{-itx} p (x) \dd x
            = \overline{\int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x}
            = \overline{\varphi (t)}.
        \end{equation*}
        \item
        \begin{equation*}
            \varphi_Y (t) = E ( \ee^{it (aX + b)} )
            = \ee^{ibt} E ( \ee^{iatX} ) = \ee^{ibt} \varphi (at).
        \end{equation*}
        \item
        因为 $ X $ 与 $ Y $ 相互独立, 所以 $ \ee^{itX} $ 与 $ \ee^{itY} $ 也是独立的, 从而有
        \begin{equation*}
            E \left( \ee^{it ( X + Y )} \right) = E \left( \ee^{itX} \ee^{itY} \right) = \varphi_X (t) \cdot \varphi_Y (t).
        \end{equation*}
        \item
        因为 $ E \left( X^l \right) $ 存在, 也就是
        \begin{equation*}
            \int_{-\infty}^{+\infty} \lvert x \rvert^l p (x) \dd x < +\infty,
        \end{equation*}
        于是含参变量 $ t $ 的广义积分 $ \int_{-\infty}^{+\infty} \ee^{itx} p(x) \dd x $ 可以对 $ t $ 求导 $ l $ 次, 于是对 $ 0 \leq k \leq l $, 有
        \begin{equation*}
            \varphi ^{(k)} (t) = \int_{-\infty}^{+\infty} i^k x^k \ee^{itx} p (x) \dd x = i^k E \left( X^k \ee^{itX} \right).
        \end{equation*}
        令 $ t = 0 $ 即得
        \begin{equation*}
            \varphi^{(k)} (0) = i^k E \left( X^k \right).
        \end{equation*}
    \end{enumerate}
    至此上述5条性质全部得证.
\end{proof}

下例是利用 \eqref{eq:4.1.6} 和 \eqref{eq:4.1.7} 来求一些常用分布的特征函数.


\begin{example}\label{exam:4.1.2}
    常用分布的特征函数 (二)

    \begin{enumerate}
        \item
        \textbf{二项分布}\index{分布!二项分布} $ b (n, p) $: 设 $ Y \sim b (n, p) $, 则 $ Y = X_1 + x_2 + \dotsb X_n $, 其中诸 $ X_i $ 是相互独立同分布的随机变量, 且 $ X_{i} \sim b (1, p) $, 由 例~\ref{exam:4.1.2} \ref{exam:4.1.1.2} 知
        \begin{equation*}
            \varphi_{X_i} (t) = p \ee^{it} + q,
        \end{equation*}
        所以由独立随机变量和的特征函数为特征函数的积, 得
        \begin{equation*}
            \varphi_Y (t) = \left( p \ee^{it} + q \right)^{\pi}
        \end{equation*}
        \item
        \textbf{正态分布}\index{分布!正态分布} $ N (\mu, \sigma^2) $: 设 $ Y \sim N (\mu, \sigma^2) $, 则 $ X = (Y - \mu) / \sigma \sim N (0, 1) $.
        由例~\ref{exam:4.1.1} 知
        \begin{equation*}
            \varphi_{X} (t) = \exp \left( -\frac{t^2}{2} \right).
        \end{equation*}
        所以由 $ Y = \sigma X + \mu $ 得
        \begin{equation*}
            \varphi_Y (t) = \varphi_{\alpha X + \mu} (t) =\ee^{i \mu t} \varphi_X ( \sigma t ) = \exp \left( i \mu t - \frac{\sigma^2 t^2}{2} \right).
        \end{equation*}
        \item 
        \textbf{伽玛分布}\index{分布!伽玛分布} $ Ga ( n, \lambda ) $: 设 $ Y \sim Ga ( n, \lambda ) $, 则$ Y = X_1 + X_2 + \dotsb + X_n $, 其中 $ X_i $ 独立同分布, 且 $ X_i \sim Exp ( \lambda ) $.
        由例~\ref{exam:4.1.1} 知
        \begin{equation*}
            \varphi_{X_i} (t) = \left( 1 - \frac{it}{\lambda} \right)^{-1}.
        \end{equation*}
        所以由独立随机变量和的特征函数为特征函数的积, 得
        \begin{equation*}
            \varphi_Y (t) = \left( \varphi_{X_i} (t) \right)^n = \left( 1 - \frac{it}{\lambda} \right)^{-n}.
        \end{equation*}
        进一步, 当 $ a $为任一正实数时, 我们可得 $ Ga ( n, \lambda ) $ 分布的特征函数为
        \begin{equation*}
            \varphi(t) = \left( 1 - \frac{it}{\lambda} \right)^{-a}.
        \end{equation*}
        \item
        $ \mathbf{\chi^2 (n)} $ \textbf{分布}\index{分布!chi2分布@$ \mathbf{\chi^2 (n)} $ 分布}: 因为 $ \chi^2 (n) = Ga ( n/2, 1/2 ) $, 所以 $ \chi^2 (n) $ 分布的特征函数为
        \begin{equation*}
            \varphi (t) = ( 1 - 2it )^{-n/2}.
        \end{equation*}
    \end{enumerate}
\end{example}

上述常用分布的特征函数汇总在表~\ref{tab:4.1.1} 中.

\begin{table}
    \renewcommand{\arraystretch}{1.6}
    \centering
    \caption{常用分布的特征函数}\label{tab:4.1.1}
    \begin{tabular}{>{\centering\arraybackslash}m{0.15\linewidth}>{\centering\arraybackslash}m{0.45\linewidth}>{\centering\arraybackslash}m{0.3\linewidth}}
        \toprule
        分布 & 分布列 $ p_k $ 或分布密度 $ p (x) $ & 特征函数 $ \varphi (t) $\\
        \midrule
        单点分布 & $ P (X = a) = 1 $ & $ \ee^{itz} $\\
        0-1分布 & $ P_k = p^k  q^{1 - k} $, $ k = 0,1 $ & $ p \ee^{it} + q $\\
        二项分布 $ b (n, p) $ & $ p_k = \binom{n}{k} p^k q^{1-k} $, $ k = 0,1,\dotsc,n $ & $ \left( p \ee^{it} + q \right)^{\pi} $\\
        泊松分布 $ P (\lambda) $ & $ P_k = ( \lambda^k/k! ) \ee^{-\lambda} $, $ k = 0, 1, \dotsc $ & $ \ee^{\lambda ( \ee^{it} ) -1} $\\
        均匀分布 $ U (a,b) $ & $ p (x) = 1/(b-a) $, $ a \leq x \leq b $ & $ \dfrac{\ee^{ibt} - \ee^{iat}}{it (b-a)} $\\
        正态分布 $ N (\mu, \sigma^2) $ & $ p (x) = \dfrac{1}{\sqrt{2\pi}\sigma} \exp \left( - \dfrac{( x - \mu )^2}{2 \sigma^2} \right) $ & $ \exp \left( i \mu t - \dfrac{\sigma^2 t^2}{2} \right) $\\
        指数分布 $ Exp ( \lambda ) $ & $ p (x) = \lambda \ee^{-\lambda x} $, $ x > 0 $ & $ \left( 1 - \dfrac{it}{\lambda} \right)^{-1} $\\
        伽玛分布 $ Ga ( a, \lambda ) $ & $ p (x) = \dfrac{\lambda^\alpha}{\Gamma (a)} x^{\alpha - 1} \ee^{-\lambda x} $, $ x \geq 0 $ & $ \left( 1 - \dfrac{it}{\lambda} \right)^{-a} $\\
        $ \chi^2 (n) $ 分布 & $ p (x) = \dfrac{x^{n/2 - 1} \ee^{-x/2}}{\Gamma (n/2) 2^{n/2}} $, $ x > 0 $ & $ ( 1 - 2it )^{-n/2} $\\
        \bottomrule
    \end{tabular}
\end{table}

下例是利用 \eqref{eq:4.1.8} 来求分布的数学期望和方差.

\begin{example}\label{exam:4.1.3}
    试利用特征函数的方法求伽玛分布 $ Ga ( n, \lambda ) $ 的数学期望和方差.
\end{example}

\begin{solution}
    因为伽玛分布 $ Ga ( a, \lambda ) $ 的特征函数及其一、二阶导数为
    \begin{gather*}
        \varphi (t) = \left( 1 - \dfrac{it}{\lambda} \right)^{-a},\\
        \varphi' (t) = \frac{ai}{\lambda} \left( 1 - \frac{it}{\lambda} \right)^{-a-1}, \ \varphi' (0) = \frac{ai}{\lambda},\\
        \varphi'' (t) = \frac{a ( a + 1 ) i^2}{\lambda^2} \left( 1 - \frac{it}{\lambda} \right)^{-a-2}, \ \varphi'' (0) = -\frac{a (a+1)}{\lambda^2},
    \end{gather*}
    所以由 \eqref{eq:4.1.9} 得
    \begin{align*}
        E (X) & = \frac{\varphi' (0)}{i} = \frac{a}{\lambda},\\
        Var (X) & = - \varphi'' (0) + \bigl( \varphi' (0) \bigr)^2 = \frac{a (a+1)}{\lambda^2} + \left( \frac{ai}{\lambda} \right)^2\\
        & = \frac{a (a+1)}{\lambda^2} - \frac{a^2}{\lambda^2} = \frac{a}{\lambda^2}.
    \end{align*}
\end{solution}

特征函数还有以下一些优良性质.

\begin{theorem}{一致连续性}{4.1.1}
    随机变量 $ X $ 的特征函数 $ \varphi (t) $ 在 $ ( -\infty, +\infty ) $ 上一致连续.
\end{theorem}

\begin{proof}
    设 $ X $ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $ p (x) $, 则对任意实数 $t$, $h$ 和正数$ a > 0 $, 有
    \begin{align*}
        \lvert \varphi ( t + h ) - \varphi (t) \rvert & = \left\lvert \int_{-\infty}^{+\infty} \bigl( \ee^{ihx} - 1 \bigr) \ee^{itx} p (x) \dd x \right\rvert\\
        & \leq \int_{-\infty}^{+\infty} \bigl\lvert \ee^{ihx} - 1 \bigr\rvert p (x) \dd x\\
        & \leq \int_{-a}^a \bigl\lvert \ee^{ihx} - 1 \bigr\rvert p (x) \dd x + 2 \int_{\lvert x \rvert \geq a} p (x) \dd x.
    \end{align*}
    对任意的 $ \varepsilon > 0 $, 先取定一个充分大的 $ a $, 使得
    \begin{equation*}
        2 \int_{\lvert x \rvert \geq a} p (x) \dd x < \frac{\varepsilon}{2},
    \end{equation*}
    然后对任意的$ x \in [-a,a] $, 只要取$ \delta = \varepsilon/(2a) $, 则当$ \lvert h \rvert < \delta $ 时, 便有
    \begin{align*}
        \lvert \ee^{ihx} - 1 \rvert & = \left\lvert \ee^{i \frac{h}{2} x} \left( \ee^{i \frac{h}{2} x} - \ee^{-i \frac{h}{2} x} \right) \right\rvert\\
        & = 2 \left\lvert \sin \frac{hx}{2} \right\rvert
        \leq 2 \left\lvert \frac{hx}{2} \right\rvert
        < ha
        < \frac{\varepsilon}{2},
    \end{align*}
    即 $ \varphi (t) $ 在 $ (-\infty, +\infty) $ 上一致连续.
\end{proof}

\begin{theorem}{非负定性}{4.1.2}
    随机变量 $ X $ 的特征函数 $ \varphi (t) $ 是非负定的, 即对任意正整数 $ n $, 及 $ n $ 个实数 $ t_1, t_2, \dotsc, t_n $ 和 $ n $ 个复数 $ z_1, z_2, \dotsc, z_n $, 有
    \begin{equation}\label{eq:4.1.10}
        \sum_{k=1}^n \sum_{j=1}^n \varphi ( t_k - t_j ) z_k \overline{z_j} \geq 0.
    \end{equation}
\end{theorem}

\begin{proof}
    仍设 $ X $ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $ p (x) $, 则有
    \begin{align*}
        \sum_{k=1}^n \sum_{j=1}^n \varphi ( t_k - t_j ) z_k \overline{z_j}
        & = \sum_{k=1}^n \sum_{j=1}^n z_k \overline{z_j} \int_{-\infty}^{+\infty} \ee^{i (t_k - t_j) x} p (x) \dd x\\
        & = \int_{-\infty}^{+\infty} \sum_{k=1}^n \sum_{j=1}^n z_k \overline{z_j} \ee^{i (t_k - t_j) x} p (x) \dd x\\
        & = \int_{-\infty}^{+\infty} \left( \sum_{k=1}^n z_k \ee^{i t_k x} \right) \left( \sum_{j=1}^n \overline{z_j} \ee^{-i t_j x} \right) p (x) \dd x\\
        & = \int_{-\infty}^{+\infty} \left\lvert \sum_{k=1}^n z_k \ee^{i t_k x} \right\lvert^2 p (x) \dd x \geq 0.
    \end{align*}
    这就证明了 \eqref{eq:4.1.10} 式.
\end{proof}

由特征函数的定义可知, 随机变量的分布惟一地确定了它的特征函数.
前面的讨论实际上都是从随机变量的分布出发, 讨论特征函数及其性质.
要注意的是: 如果两个分布的数学期望、方差及各阶矩都相等, 也无法证明此两个分布相等.
但特征函数却不同, 它有着比数学期望、方差及各阶矩更优良的性质: 即特征函数也完全决定了分布, 也就是说, 两个分布函数相等当且仅当它们所对应的特征函数相等.

以下定理~\ref{thm:4.1.3} 给出了由特征函数求分布函数的公式, 定理~\ref{thm:4.1.5} 给出了连续随机变量时由特征函数求密度函数的公式.
而定理~\ref{thm:4.1.4} 说明了分布函数与特征函数是一一对应的.

\begin{theorem}{逆转公式}{4.1.3}
    设 $ F (x) $ 和 $ \varphi (t) $ 分别为随机变量 $ X $ 的分布函数和特征函数, 则对 $ F (x) $ 的任意两个连续点 $ x_1 < x_2 $, 有
    \begin{equation}\label{eq:4.1.11}
        F (x_2) - F (x_1) = \lim_{T \to \infty} \frac{1}{2\pi} \int_{-T}^T \frac{\ee^{-itx_1}  - \ee^{-itx_2}}{it} \varphi (t) \dd t.
    \end{equation}
\end{theorem}

\begin{proof}
    设 $ X $ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $ p (x) $ .
    记
    \begin{align*}
        J_T & = \frac{1}{2\pi} \int_{-T}^T \frac{\ee^{-itx_1}  - \ee^{-itx_2}}{it} \varphi (t) \dd t\\
        & = \frac{1}{2\pi} \int_{-T}^T \left[ \int_{-\infty}^{+\infty} \frac{\ee^{-itx_1}  - \ee^{-itx_2}}{it} \ee^{itx} p (x) \right] \dd t.
    \end{align*}
    对任意的实数 $ a $, 有
    \begin{equation*}
        \left\lvert \ee^{ia} -1 \right\rvert \leq \lvert a \rvert,
    \end{equation*}
    事实上, 对 $ a \geq 0 $ 有
    \begin{equation*}
        \left\lvert \ee^{ia} - 1 \right\rvert = \left\lvert \int_0^t \ee^{ix} \dd x \right\rvert \leq \int_0^a \left\lvert \ee^{ix} \right\rvert \dd x = 0.
    \end{equation*}
    对 $ a < 0 $, 有
    \begin{equation*}
        \left\lvert \ee^{ia} - 1 \right\rvert = \left\lvert \ee^{ia} \left( \ee^{\lvert a \rvert} - 1 \right) \right\rvert = \left\lvert \ee^{i \lvert a \rvert} - 1 \right\rvert \leq \lvert a \rvert.
    \end{equation*}
    因此
    \begin{equation*}
        \left\lvert \frac{\ee^{-itx_1} - \ee^{-itx_2}}{it} \ee^{itx} \right\rvert \leq x_2 - x_1.
    \end{equation*}
    即 $ J_T $ 中被积函数有界, 所以可以交换积分次序, 从而得
    \begin{align*}
        J_T & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \left[ \int_{-T}^{T} \frac{\ee^{-itx_1} - \ee^{-itx_2}}{it} \ee^{itx} \dd t \right] p (x) \dd x\\
        & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \left[ \int_{0}^{T} \frac{\ee^{it(x - x_1)} - \ee^{-it (x - x_1)} - \ee^{it (x - x_2)} + \ee^{-it (x - x_2)}}{it} \dd t \right] p (x) \dd x\\
        & = \frac{1}{\pi} \int_{-\infty}^{+\infty} \left[ \int_{0}^{T} \left(\frac{\sin t (x - x_1)}{t} - \frac{\sin t (x - x_2)}{t} \right) \dd t \right] p (x) \dd x.
    \end{align*}
    又记
    \begin{equation*}
        g (T, x, x_1, x_2) = \frac{1}{\pi} \int_{0}^{T} \left(\frac{\sin t (x - x_1)}{t} - \frac{\sin t (x - x_2)}{t} \right) \dd t,
    \end{equation*}
    则由数学中的狄利克雷积分
    \begin{equation*}
        D (a) = \frac{1}{\pi} \int_0^{+\infty} \frac{\sin at}{t} \dd t =
        \begin{cases}
            \dfrac{1}{2}, & a > 0,\\
            0, & a = 0,\\
            -\dfrac{1}{2}, & a < 0.
        \end{cases}
    \end{equation*}
    知
    \begin{equation*}
        \lim_{t \to +\infty} g (T, x, x_1, x_2) = D (x - x_1) - D (x - x_2).
    \end{equation*}
    分别考察 $ x $ 在区间 $ (x_1, x_2) $ 的端点及内外时狄利克雷积分的值即可得
    \begin{equation*}
        \lim_{t \to +\infty} g (T, x, x_1, x_2) =
        \begin{cases}
            0, & x < x_1 \ \text{或} \ x > x_2,\\
            \dfrac{1}{2}, & x = x_1 \ \text{或} \ x = x_2,\\
            1, & x_1 < x < x_2,
        \end{cases}
    \end{equation*}
    且 $ \lvert g (T, x, x_1, x_2) \rvert $ 有界, 从而可以把积分号和极限号互换, 故有
    \begin{align*}
        \lim_{T \to +\infty} J_T & = \int_{-\infty}^{+\infty} \lim_{T \to +\infty} g (T, x, x_1, x_2) p (x) \dd x\\
        & = \int_{x_1}^{x_2} p (x) \dd x = F (x_2) - F (x_1).
    \end{align*}
    定理得证.
\end{proof}

\begin{theorem}{唯一性定理}{4.1.4}
    随机变量的分布函数由其特征函数唯一决定.
\end{theorem}

\begin{proof}
    对 $ F (x) $ 的每一个连续点 $ x $, 当 $ y $ 沿着 $ F (x) $ 的连续点趋于 $ -\infty $ 时, 由逆转公式得
    \begin{equation*}
        F (x) = \lim_{y \to -\infty} \lim_{T \to +\infty} \frac{1}{2\pi} \int_{-T}^T \frac{\ee^{-ity} - \ee^{-itx}}{it} \varphi (t) \dd t,
    \end{equation*}
    而分布函数由其连续点上的值惟一决定, 故结论成立.
\end{proof}

由于分布函数 $ F (x) $ 是非降函数， 因此我们一定能做到让 $ y $ 沿着 $ F (x) $ 的连续点趋于 $ -\infty $, 并且 $ F (x) $ 由其连续点上的值唯一确定, 而这些性质的证明在此从略了.

特别, 当 $ X $ 为连续随机变量, 有下述更强的结果.
\begin{theorem}{}{4.1.5}
    若 $ X $ 为连续随机变量, 其密度函数为 $ p (x) $, 特征函数为 $ \varphi (t) $.
    如果 $ \int_{-\infty}^{+\infty} \lvert \varphi (t) \rvert \dd t < +\infty $, 则
    \begin{equation}\label{eq:4.1.12}
        p (x) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-itx} \varphi (t) \dd t.
    \end{equation}
\end{theorem}

\begin{proof}
    记 $ X $ 的分布函数为 $ F (x) $, 由逆转公式知
    \begin{align*}
        p (x) & = \lim_{\Delta x \to 0} \frac{F (x + \Delta x) - F (x)}{\Delta x}\\
        & = \lim_{\Delta x \to 0} \frac{1}{2\pi} \int_{-\infty}^{+\infty} \frac{\ee^{-itx} - \ee^{-it (x + \Delta x)}}{it \cdot \Delta x} \varphi (t) \dd t.
    \end{align*}
    再次利用不等式 $ \lvert \ee^{ia} - 1 \rvert \leq \lvert a \rvert $, 就有
    \begin{equation*}
        \left\lvert \frac{\ee^{-itx} - \ee^{-it (x + \Delta x)}}{it \cdot \Delta x} \right\rvert \leq 1.
    \end{equation*}
    又因为 $ \int_{-\infty}^{+\infty} \lvert \varphi (t) \rvert < +\infty $, 所以可以交换极限号和积分号, 即
    \begin{align*}
        p (x) & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \lim_{\Delta x \to 0} \frac{\ee^{-itx} - \ee^{-it (x + \Delta x)}}{it \cdot \Delta x} \varphi (t) \dd t\\
        & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-itx} \varphi (t) \dd t.
    \end{align*}
    定理得证.
\end{proof}

\eqref{eq:4.1.12} 在数学分析中也称为傅里叶逆变换, 所以 \eqref{eq:4.1.3} 和 \eqref{eq:4.1.12} 实质上是一对互逆的变换:
\begin{gather*}
    \varphi (t) = \int_{-\infty}^{+\infty} \ee^{itx} p (x) \dd x,\\
    P (x) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-itx} \varphi (t) \dd t.
\end{gather*}
即特征函数是密度函数的傅里叶变换, 而密度函数是特征函数的傅星叶逆变换

在此着重指出: 在概率论中, 独立随机变量和的问题占有``中心''地位, 用卷积公式去处理独立随机变量和的问题是相当复杂, 而引入了特征函数可以很方便地用特征函数相乘求得独立随机变量和的特征函数, 由此大大简化了处理独立随机变量和的难度.
读者可从下例中体会出这一点.

\begin{example}\label{exam:4.1.4}
    在 3.3.4 节中, 我们用卷积公式通过复杂的计算证明了二项分布、泊松分布、伽玛分布和 $ \chi^2 $ 分布的可加性.
    现在用特征函数方法 (性质~\ref{prop:4.1.4} 和唯一性定理) 可以很方便地证明正态分布的可加性.
    设 $ X \sim N ( \mu_1, \sigma_1^2) $, $ Y \sim N ( \mu_2, \sigma_2^2) $ 且 $ X $ 与 $ Y $ 独立.
    因为
    \begin{equation*}
        \varphi_X (t) = \exp \left( it\mu_1 - \frac{\sigma_1^2 t^2}{2} \right), \ \varphi_Y (t) = \exp \left( it\mu_2 - \frac{\sigma_2^2 t^2}{2} \right)
    \end{equation*}
    所以由性质~\ref{prop:4.1.4} 得
    \begin{equation*}
        \varphi_{X+Y} (t) = \varphi_X (t) \cdot \varphi_Y (t) = \exp \left( it ( \mu_1 + \mu_2 ) - \frac{(\sigma_1^2 + \sigma_2^2) t^2}{2} \right).
    \end{equation*}
    这正是 $ N ( \mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2 ) $ 的特征函数, 再由特征函数的唯一性定理, 即知
    \begin{equation*}
        X + Y \sim N ( \mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2 ).
    \end{equation*}
    同理可证: 若 $ X_j $ 相互独立, 且 $ X_j \sim N ( \mu_j, \sigma_j^2 ) $, $ j = 1,2,\dotsc,n $, 则
    \begin{equation*}
        \sum_{j=1}^n X_j \sim N \left( \sum_{j=1}^n \mu_j, \sum_{j=1}^n \sigma_J^2 \right).
    \end{equation*}
\end{example}

\begin{example}
    已知连续随机变量的特征函数如下, 求其分布.
    \begin{enumerate}
        \item $ \varphi_1 (t) = \ee^{- \lvert t \rvert} $,
        \item $ \varphi_2 (t) = \frac{\sim at}{at} $.
    \end{enumerate}
\end{example}

\begin{solution}
    \begin{enumerate}
        \item 由逆转公式 \eqref{eq:4.1.12} 可知其密度函数为
        \begin{align*}
            p (x) & = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \ee^{-ixt} \cdot \ee^{- \lvert t \rvert} \dd t\\
            & = \frac{1}{2\pi} \int_{0}^{+\infty} \ee^{- (1 + ix)t} \dd t + \frac{1}{2\pi} \int_{-\infty}^{0} \ee^{(1 - ix)t} \dd t\\
            & = \frac{1}{2\pi} \left( \frac{1}{1 + ix} + \frac{1}{1 - ix} \right) = \frac{1}{\pi ( 1 + x^2 )}
        \end{align*}
        这是柯西分布, 所以特征函数 $ \varphi_1 (t) = e^{-\lvert t \rvert} $ 对应的是柯西分布.
        \item $ \varphi_2 (t) = \sin at / at $ 是均匀分布 $ U ( -a, a ) $ 的特征函数, 由唯一性定理知, 该特征函数对应的分布不是别的, 只能是均匀分布 $ U ( -a, a ) $.
    \end{enumerate}
\end{solution}

\begin{xiti}
    \item 设离微随机变量 $ X $ 的分布列如下, 试求 $ X $ 的特征函数.
    
    \begin{tabularx}{0.95\linewidth}{>{\centering\arraybackslash}X|*{5}{>{\centering\arraybackslash}X}}
        \toprule
        $X$ & 0 & 1 & 2 & 3\\
        \midrule
        $P$ & 0.4 & 0.3 & 0.2 & 0.1\\
        \bottomrule
    \end{tabularx}
    \item 设离散随机变量 $ X $ 服从几何分布
    \begin{equation*}
        P ( X = k ) = ( 1 - p )^{k - 1} p, \ k=1,2,\dotsc.
    \end{equation*}
    试求 $ X $ 的特征函数, 并以此求 $ E ( X ) $ 和 $ Var ( X ) $.
    \item 设离散随机变量 $ X $ 服从巴斯卡分布
    \begin{equation*}
        P ( X = k ) = \binom{k - 1}{r - 1} p^r ( 1 - p )^{k - r}, \ k=r, r+1, \dotsc.
    \end{equation*}
    试求 $ X $ 的特征函数.
    \item 求下列分布函数的特征函数, 并由特征函数求其数学期望和方差.
    \begin{enumerate}
        \item $ F_1 (x) = a/2 \int_{-\infty}^x \ee^{-a \lvert x \rvert} \dd x, \ ( a > 0 ) $.
        \item $ F_2 (x) = a/\pi \int_{-\infty}^x \frac{1}{x^2 + a^2} \dd x, \ ( a > 0 ) $.
    \end{enumerate}
    \item 设 $ X \sim N ( \mu, \sigma^2 ) $, 试用特征函数的方法求 $ X $ 的3阶及4阶中心矩.
    \item 试用特征函数的方法证明二项分布的可加性: 若 $ X \sim b ( m, p ) $, $ Y \sim b ( m, p ) $, 且 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim b ( n + m, p ) $.
    \item 试用特征函数的方法证明泊松分布的可加性: 若 $ X \sim P ( \lambda_1 ) $, $ Y \sim P ( \lambda_2 ) $, 目 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim P ( \lambda_1 + \lambda_2 ) $.
    \item 试用特征函数的方法证明伽玛分布的可加性: 若 $ X \sim Ga ( a_1, \lambda ) $, $ Y \sim Ga ( a_1, \lambda ) $, 且 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim Ga ( a_1 + a_2, \lambda ) $.
    \item 试用特征函数的方法证明 $ \chi^2 $ 分布的可加性: 若 $ X \sim \chi^2 ( n ) $, $ Y \sim \chi^2 ( m ) $, 且 $ X $ 与 $ Y $ 独立, 则 $ X + Y \sim \chi^2 ( m + n ) $.
    \item 设 $ X_i $ 独立同分布, 且 $ X_i \sim Exp ( \lambda ) $, $ i = 1,2,\dotsc,n $. 试用特征函敷的方法证明: $ Y_n = \sum_{i=1}^n X_i \sim Ga ( n, \lambda ) $.
    \item 设连续随机变量 $ X $ 的密度函数如下:
    \begin{equation*}
        p (x) = \frac{1}{\pi} \cdot \frac{\lambda}{\lambda^2 + ( x - \mu )^2}, \ -\infty < x < +\infty.
    \end{equation*}
    其中参数 $ \lambda > 0 $, $ -\infty < \mu < +\infty $. 试证
    \begin{enumerate}
        \item $ X $ 的特征函数为 $ \exp \bigl( i\mu t - \lambda \lvert t \rvert \bigr) $, 且利用此结果证明柯西分布的可加性.
        \item 当 $ \mu = 0 $, $ \lambda = 1 $ 时, 记 $ Y = X $, 试证 $ \varphi_{X + Y} (t) = \varphi_X (t) \cdot \varphi_Y (t) $, 但是 $ X $ 与 $ Y $ 不独立.
        \item 若 $ X_1, X_2, \dotsc, X_n $ 相互独立, 且服从同一柯西分布, 试证: $ (1/n) ( X_1 + X_2 + \dotsb + X_n ) $ 与 $ X_1 $ 同分布.
    \end{enumerate}
    \item 设连续随机变量 $ X $ 的密度函数为 $ p (x) $, 试证: $ p (x) $ 关于原点对称的充要条件是它的特征函数是实的偶函数.
    \item 设 $ X_1, X_2, \dotsc, X_n $ 独立同分布, 且都服从 $ N (\mu, \sigma^2) $ 分布, 试求 $ \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i $ 的分布.
\end{xiti}

\section{大数定律}\label{sec:4.2}

``概率是频率的稳定值'', 其中``稳定''一词是什么含义?
在第一章我们从直观上描述稳定性: 频率在其概率附近摆动.
但如何摆动仍没说清楚, 现在可用大数定律来彻底说清这个问题了.

大数定律有多种形式, 下面从最简单的伯努利大数定律说起, 逐步介绍各种大数定律.

\subsection{伯努利大数定律}

记 $ \mu_n $ 为 $ n $ 重伯努利试验中事件 $ A $ 出现的次数, 称 $ \mu_n / n $ 为事件 $ A $ 出现的频率.

如果记一次试验中 $ A $ 发生的概率为 $ p $, 则 $ \mu_n $ 服从二项分布 $ b (n, p $, 因此频率 $ \mu_n / n $ 的数学期望与方差分别为
\begin{equation}\label{eq:4.2.1}
    E \left( \frac{\mu_n}{n} \right) = p, \ Var \left( \frac{\mu_n}{n} \right) = \frac{p ( 1 - p )}{n}.
\end{equation}

下面我们讨论 $ n \to +\infty $ 时, 频率 $ \mu_n / n $ 的极限状态.

由 \eqref{eq:4.2.1} 式, 当 $ n \to +\infty $  时, 频率的数学期望 $ p $ 保持不变, 而方差趋于0.
我们已经知道方差为0的随机变量是常数, 那么现在的问题是频率 $ \mu_n / n $ 是如何``收敛于''概率 $ p $, 即我们如何来理解``收敛''一词.

按数学分析中的数列极限概念, 数列 $ \{ \mu_n / n \} $ 的极限为 $ p $,
\begin{equation*}
    \lim_{n \to +\infty} \frac{\mu_n}{n} = p,
\end{equation*}
即对任意的 $ \varepsilon > 0 $, 当 $ n $ 充分大时, ``必定''有
\begin{equation*}
    \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon,
\end{equation*}
而其对立事件
\begin{equation*}
    \left\lvert \frac{\mu_n}{n} - p \right\rvert \geq \varepsilon,
\end{equation*}
是``必定''不会发生的.
然而在随机现象中各种情况都可能出现, 甚至事件``$ \mu_n = n $''也是可能发生的, 因为 $ p ( \mu_n = n )=p^n > 0 $, 即事件``$ \mu_n = n $''的概率大于零, 从而事件
\begin{equation*}
    \left\lvert \frac{\mu_n}{n} - p \right\rvert \geq \varepsilon,
\end{equation*}
就有可能发生.
这说明用数学分析中的极限来描述频率的极限是不妥当的, 是对频率随机性的认识不足的表现.

为此, 频率``收敛于''概率用以下方式描述是合适的: 当 $ n $ 充分大时, 频率 $ \mu_n / n $ 与概率 $ p $间有大偏差的概率很小, 而且随着 $ n $ 的增大, 它愈来愈小.
用数学语言来讲, 就是对任意的 $ \varepsilon > 0 $, 有
\begin{equation}\label{eq:4.2.2}
    \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) = 1.
\end{equation}
或
\begin{equation}\label{eq:4.2.3}
    \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert \geq \varepsilon \right) = 0.
\end{equation}
这种收敛性就称作\textbf{依概率收敛}\index{收敛!依概率收敛}, 它的一般定义将在 \S 4.3 节中给出.
下面的伯努利大数定律就是对上述讨论作了一个很好的总结.
\begin{theorem}{伯努利大数定律}{4.2.1}
    设 $ \mu_n $ 为 $ n $ 重伯努利试验中事件 A 发生的次数, $ p $为每次试验中 A 出现的概率, 则对任意的 $ \varepsilon > 0 $, 有
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) = 1.
    \end{equation*}
\end{theorem}

\begin{proof}
    因为 $ \mu_n \sim b ( n, p ) $, 且 $ \mu_n $ 的数学期望和方差如 \eqref{eq:4.2.1} 式所示.
    所以由切比雪夫不等式得
    \begin{equation}
        1 \geq P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) \geq 1 - \frac{Var (\mu_n / n)}{\varepsilon^2} = 1 - \frac{p ( 1 - p )}{n \varepsilon^2}.
    \end{equation}
    当 $ n \to + \infty $ 时, 上式右端趋于1, 因此
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{\mu_n}{n} - p \right\rvert < \varepsilon \right) = 1.
    \end{equation*}
    结论得证.
\end{proof}

伯努利大数定律说明: 随着 $ n $的增大, 事件A发生的频率 $ \mu_n / n $ 与其频率 $ p $ 的偏差 $ \lvert \mu_n / n - p \rvert $ 大于预先给定的精度 $ \varepsilon $ 的可能性愈来愈小, 小到可以忽略不计.
这就是频率稳定于概率的含义, 或者说频率依概率收敛于概率.

譬如, 抛一枚硬币出现正面的概率 $ p = 0.5 $.
若把这枚硬币连抛10次, 则因为 $ n $ 较小, 发生大偏差的可能性有时会大一些, 有时会小一些.
若把这枚硬币连抛 $ n $,当 $ n $ 很大时, 由切比雪夫不等式知: 正面出现的频率与0.5的偏差大于预先给定的精度 $ \varepsilon $ (若取精度 $ \varepsilon = 0.01 $) 的可能性
\begin{equation*}
    P \left( \left\lvert \frac{\mu_n}{n} - 0.5 \right\vert > 0.01 \right) \leq \frac{0.5 \times 0.5}{n 0.01^n} = \frac{10^4}{4n}.
\end{equation*}
当 $ n = 10^5 $ 时, 大偏差发生的可能性小于 $ 1/40 = \SI{2.5}{\percent} $.
当 $ n = 10^6 $ 时, 大偏差发生的可能性小于 $ 1/400 = \SI{0.25}{\percent} $.
可见试验次数愈多，偏差发生的可能性愈小.

伯努利大数定律提供了用频率来确定概率的理论依据.
譬如要估计某种产品的不合格品率 $ p $, 则可从该种产品中随机抽取 $ n $ 件, 当 $ n $ 很大时, 这 $ n $ 件产品中的不合格品的比例可作为不合格品率 $ p $ 的估计值.

\begin{example}[(用蒙特卡洛方法计算定积分 (随机投点法))]\label{exam:4.2.1}
    设 $ 0 \leq f (x) \leq 1 $, 求 $ f (x) $ 在区间 $ [0, 1] $ 上的积分值:
    \begin{equation*}
        J = \int_0^1 f (x) \dd x.
    \end{equation*}
    设 $ (X,Y) $ 服从正方形 $ \{ 0 \leq x \leq 1, 0 \leq y \leq 1 \} $ 上的均匀分布, 则可知 $ X $ 服从 $ [ 0, 1 ] $ 上的均匀分布, $ Y $ 也服从 $ [ 0, 1 ] $ 上的均匀分布, 且 $ X $ 与 $ Y $ 独立.
    又记事件
    \begin{equation*}
        A = \{ Y \leq f (X) \},
    \end{equation*}
    则 $ A $ 的概率为
    \begin{equation*}
        p = P ( Y \leq f (x) ) = \int_0^1 \int_0^{f(x)} \dd y \dd x = \int_0^1 f (x) \dd x = J.
    \end{equation*}
    即定积分的值 $ J $ 就是事件 $ A $ 的概率 $ p $.
    由伯努利大数定律, 我们可以用重复试验中 $ A $ 出现的额率作为 $ p $ 的估计值.
    这种求定积分的方法也称为随机投点法, 即将 $ (X, Y) $ 看成是向正方形 $ \{ 0 \leq x \leq 1, 0 \leq y \leq 1 \} $ 内的随机投点, 用随机点落在区域 $ \{ y \leq f (x) \} $ 中的频率作为定积分的近似值.
    下面用蒙特卡洛方法, 来得到 $ A $ 出现的频率:
    \begin{enumerate}
        \item 先用计算机产生 $ (0, 1) $ 上均匀分布的 $ 2n $个随机数: $ x_i, y_i $, $ i=1, 2, \dotsc, n$, 这里 $ n $ 可以很大, 臂如 $ n = 10^4 $, 甚至 $ n = 10^5 $.
        \item 对 $ n $ 对数据 $ (x_i, y_i) $, $ i=1, 2, \dotsc, n $, 记录满足如下不等式
        \begin{equation*}
            y_i \leq f (x)
        \end{equation*}
        的次数, 这就是事件A发生的频数 $ \mu_n $.
        由此可得事件 $ A $发生的频率 $ \mu_n / n $, 则 $ J \approx \mu_n / n $.
    \end{enumerate}

    譬如计算 $ \int_0^1 \ee^{-x^2/2}/\sqrt{2\pi} \dd x $, ，其精确值和 $ n = 10^4 $, $ n = 10^5 $ 时的模拟值如下

    \begin{tabularx}{0.9\linewidth}{*{3}{>{\centering\arraybackslash}X}}
        \toprule
        精确值 & $ n = 10^4 $ & $ n = 10^5 $ \\
        \midrule
        \num{0.341344} & \num{0.340698} & \num{0.341355}\\
        \bottomrule
    \end{tabularx}

    注意，对于一般区间 $ [a, b] $ 上的定积分
    \begin{equation*}
        J' = \int_a^b g (x) \dd x,
    \end{equation*}
    作线性变换 $ y=(x-a)/(b-a) $, 即可化成 $ [0, 1] $ 区间上的积分.
    进一步若 $ c \leq g(x) \leq d$, 可令
    \begin{equation*}
        f (y) = \frac{1}{d-c} \bigl( g ( a + ( b - a ) y ) - c \bigr),
    \end{equation*}
    则 $ 0 \leq f (y) \leq 1 $.
    此时有
    \begin{equation*}
        J' = \int_a^b g (x) \dd x = S_0 \int_0^1 f (y) \dd y + c ( b - a ).
    \end{equation*}
    其中 $ S_0 = ( b -a ) ( d - c ) $.
    这说明以上用蒙特卡洛方法计算定积分方法带有普遍意义.
\end{example}

\subsection{常用的几个大数定律}

\subsubsection{大数定律的一般形式}

伯努利大数定律讨论的是一个相互独立同分布的随机变量序列 $ \{ X_n \} $, 其共同分布为二点分布.
若记
\begin{equation*}
    X_i =
    \begin{cases}
        1, & \text{第} \ i \ \text{次试验中事件} \ A \ \text{发生},\\
        0, & \text{第} \ i \ \text{次试验中事件} \ A \ \text{不发生},
    \end{cases}
    \quad i=1,2,\dotsc,n,\dotsc,
\end{equation*}
则 $ \{ X_n \} $ 是独立的二点分布随机变量序列, 现考察该序列的前 $ n $ 个随机变量之和 $ \mu_n = \sum_{i=1}^n X_i $, 其频率及频率的数学期望分别为
\begin{equation*}
    \frac{\mu_n}{n} \frac{1}{n} \sum_{i=1}^n X_i, \quad p = E \left( \frac{1}{n} \sum_{i=1}^n X_i \right) = \frac{1}{n} \sum_{i=1}^n E (X_i).
\end{equation*}
那么伯努利大数定律的结论为: 对任意的 $ \varepsilon > 0 $, 有
\begin{equation}\label{eq:4.2.5}
    \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n X_i - \frac{1}{n} \sum_{i=1}^n E (X_i) \right\rvert < \varepsilon \right) = 1.
\end{equation}
一般的大数定律都涉及一个随机变量序列 $ \{ X_n \} $, 大数定律的结论都是形如 \eqref{eq:4.2.5}, 为此我们给出如下定义.

\begin{definition}{}{4.2.1}
    设有一随机变量序列 $ \{ X_n \} $, 假如它具有形如 \eqref{eq:4.2.5} 的性质, 则称该随机变量序列 $ \{ X_n \} $ 服从\textbf{大数定律}\index{大数定律}.
\end{definition}

不同的大数定律的差别只是对不同的随机变量序列 $ \{ X_n \} $ 而言, 有的是相互独立的随机变量序列, 有的是相依的随机变量序列, 有的是同分布的随机变量序列, 有的是不同分布的随机变量序列等等.

\subsubsection{切比需夫大数定律}

利用切比雪夫不等式就可证明下面的切比雪夫大数定律.

\begin{theorem}{切比需夫大数定律}{4.2.2}
    设 $ \{ X_n \} $ 为一列两两不相关的随机变量序列, 若每个 $ X_i $ 的方差存在, 且有共同的上界, 即 $ Var (X) \le c $, $ i=1,2, \dotsc $, 则 $ \{ X_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $,  \eqref{eq:4.2.5}  成立.
\end{theorem}

\begin{proof}
    因为 $ \{ X_n \} $ 两两不相关, 故
    \begin{equation*}
        Var \left( \frac{1}{n} \sum_{i=1}^n X_i \right) = \frac{1}{n^2} \sum_{i=1}^n Var \bigl( X_i \bigr) \leq \frac{c}{n}.
    \end{equation*}
    再由切比雪夫不等式得到: 对任意的 $ \varepsilon > 0 $, 有
    \begin{equation*}
        P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n X_i - \frac{1}{n} \sum_{i=1}^n E \bigl( X_i \bigr) \right\rvert < \varepsilon \right) \geq 1 - \frac{Var\left( \frac{1}{n} \sum_{i=1}^n X_i \right)}{\varepsilon^2} \geq 1 - \frac{c}{n\varepsilon^2}.
    \end{equation*}
    于是当 $ n \to +\infty $ 时, 有
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n X_i - \frac{1}{n} \sum_{i=1}^n E \bigl( X_i \bigr) \right\rvert < \varepsilon \right) = 1.
    \end{equation*}
\end{proof}

注意, 切比雪夫大数定律只要求 $ \{ X_n \} $ 互不相关, 并不要求它们是同分布的.
假如 $ \{ X_n \} $ 是独立同分布的随机变量序列, 且方差有限, 则 $ \{ X_n \} $ 必定服从大数定律.

\begin{example}\label{exam:4.2.2}
    设 $ \{ X_n \} $ 是独立同分布的随机变量序列, $ E \bigl( X_n^4 \bigr) < +\infty $. 若令 $ E \bigl( X_n^4 \bigr) < +\infty $, $ Var \bigl( X_n \bigr)= \sigma^2 $, 考察
    \begin{equation*}
        Y_n = \bigl( X_n - \mu \bigr)^2, \quad n = 1, 2, \dotsc,
    \end{equation*}
    则随机变量序列 $ \{ Y_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $, 有
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n \bigl( X_i - \mu \bigr)^2 - \sigma^2 \right\rvert \geq \varepsilon \right) = 0.
    \end{equation*}
\end{example}

\begin{proof}
    显然 $ \{ Y_n \} $ 是独立同分布随机变量序列, 其方差
    \begin{equation*}
        Var \bigl( Y_n \bigr) = Var \bigl( X_n - \mu \bigr)^2 = E \bigl( X_n - \mu \bigr)^4 - \sigma^4.
    \end{equation*}
    由于 $ E \bigl( X_n^4 \bigr) $ 存在, 故 $ E \bigl( X_n^3 \bigr) $ ,  $ E \bigl( X_n^2 \bigr) $ 皆存在, 从而 $ E \bigl( X_n - \mu \bigr)^4 $ 也存在.
    由切比雪夫大数定律知
    \begin{equation*}
        \lim_{n \to +\infty} P \left( \left\lvert \frac{1}{n} \sum_{i=1}^n Y_i - \frac{1}{n} \sum_{i=1}^n E \bigl( Y_i \bigr) \right\rvert \geq \varepsilon \right) = 0.
    \end{equation*}
    其中
    \begin{equation*}
        \frac{1}{n} \sum_{i=1}^n Y_n = \frac{1}{n} \sum_{i=1}^n \bigl( X_i - \mu \bigr)^2, \ \frac{1}{n} \sum_{i=1}^n E \bigl( Y_n \bigr) = \sigma^2.
    \end{equation*}
    故 $ \{ Y_n \} $ 服从大数定律.
\end{proof}

\subsubsection{马尔可夫大数定律}

注意到以上大数定律的证明中, 只要有
\begin{equation*}\label{eq:4.2.6}
    \frac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) \to 0.
\end{equation*}
则大数定律就能成立.
这个条件 \ref{eq:4.2.6} 被称为\textbf{马尔可夫条件}\index{马尔可夫条件}.

\begin{theorem}{马尔可夫大数定律}{4.2.3}
    对随机变量序列 $ \{ X_n \} $, 若 \ref{eq:4.2.6} 成立, 则 $ \{ X_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $, \eqref{eq:4.2.5} 成立.
\end{theorem}

\begin{proof}
    利用切比雪夫不等式即可证得.
\end{proof}

马尔可夫大数定律的重要性在于: 对 $ \{ X_n \} $ 已经没有任何同分布、独立性、不相关的假定.
切比雪夫大数定律显然可由马尔可夫大数定律推出.

\begin{example}\label{exam:4.2.3}
    设 $ \{ X_n \} $ 为一同分布、方差存在的随机变量序列, 且 $ X_n $ 仅与 $ X_{n-1} $ 和 $ X_{n+1} $ 相关, 而与其他的 $ X_i $ 不相关.
    试问该随机变量序列 $ \{ X_n \} $ 是否服从大数定律？
\end{example}

\begin{proof}
    $ \{ X_n \} $ 为相依随机变量序列, 考虑其马尔可夫条件
    \begin{equation*}
        \frac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) = \frac{1}{n^2} \left( \sum_{i=1}^n Var \bigl( X_i \bigr) + 2 \sum_{i=1}^{n-1} Cov \bigl( X_i, X_{i-1} \bigr) \right)
    \end{equation*}
    记 $ Var ( X_i ) = \sigma^2 $, 则 $ \lvert Cov ( X_i, X_j ) \rvert \leq \sigma^2 $, 于是有
    \begin{equation*}
        \frac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) \leq \frac{1}{n^2} \bigl( n \sigma^2 + 2 ( n - 1 ) \sigma^2 \bigr) \to 0, \ ( n \to +\infty ),
    \end{equation*}
    即马尔可夫条件成立, 故 $ \{ X_n \} $ 服从大数定律.
\end{proof}

\subsubsection{辛钦大数定律}

我们已经知道, 一个随机变量的方差存在, 则其数学期望必定存在; 但反之不成立, 即一个随机变量的数学期望存在, 则其方差不一定存在.
以上几个大数定律均假设随机变量序列 $ \{ X_n \} $ 的方差存在, 以下的辛钦大数定律去掉了这一假设, 仅设每个 $ X_i $ 的数学期望存在, 但同时要求 $ \{ X_n \} $ 为独立同分布的随机变量序列.
伯努利大数定律仍然是辛钦大数定律的特例.

\begin{theorem}{辛钦大数定律}{4.2.4}
    设 $ \{ X_n \} $ 为一独立同分布的随机变量序列, 若 $ X_i $ 的数学期望存在, 则 $ \{ X_n \} $ 服从大数定律, 即对任意的 $ \varepsilon > 0 $, \eqref{eq:4.2.5} 成立.
\end{theorem}

这个定理的证明要用到特征函数这一工具, 在下一节中给出具体证明.

辛钦大数定律提供了求随机变量数学期望 $ E ( X ) $ 的近似值的方法.
设想对随机变量 $ X $ 独立重复地观察 $ n $ 次, 第 $ k $ 次观察值为 $ X_k $, 则 $ X1,X2, \dotsc, X_n $ 应该是相互独立的, 且它们的分布应该与 $ X $ 的分布相同.
所以, 在 $ E (X) $ 存在的条件下, 按照辛钦大数定律, 当 $ n $ 足够大时, 可以把平均观察值
\begin{equation*}
    \frac{1}{n} \sum_{i=1}^n X_i
\end{equation*}
作为 $ E ( X ) $ 的近似值.
这样做法的一个优点是我们可以不必去管 $ X $ 的分布究竟是怎样的, 我们的目的只是寻求数学期望.

事实上, 用观察值的平均去作为随机变量的均值在实际生活中是常用的方法.
管如, 用观察到的某地区 \num{5000} 个人的平均寿命作为该地区的人均寿命的近似值是合适的, 这样做法的依据就是辛钦大数定律.

\begin{example}[(用蒙特卡洛方法计算定积分 (平均值法))]\label{exam:4.2.4}
    为计算定积分
    \begin{equation*}
        J = \int_0^1 f (x) \dd x.
    \end{equation*}
    设随机变量 $ X $ 服从 $ ( 0, 1 ) $ 上的均匀分布, 则 $ Y = f (X) $ 的数学期望为
    \begin{equation*}
        E \bigl( f (X) \bigr) = \int_0^1 f (x) \dd x = J.
    \end{equation*}
    所以估计 $ J $ 的值就是估计 $ f (X) $ 的数学期望的值.
    由辛钦大数定律， 可以用 $ f (X) $ 的观察值的平均去估计 $ f (X) $ 的数学期望的值.
    具体做法如下: 先用计算机产生 $ n $ 个 $ (0, 1) $ 上均匀分布的随机数: $ x_i $, $ i = 1, 2, \dotsc, n $. 然后对每个 $ x_i $ 计算 $ f (x_i) $, 最后得 $ J $ 的估计值为
    \begin{equation*}
        J \approx \frac{1}{n} \sum_{i=1}^n f (x_i).
    \end{equation*}

    譬如计算 $ \int_0^1 \ee^{-x^2/2} / \sqrt{2\pi} \dd x $, 其精确值和 $ n = 10^4 $, $ n = 10^5 $ 时的模拟值如下:

    \begin{tabularx}{0.9\linewidth}{*{3}{>{\centering\arraybackslash}X}}
        \toprule
        精确值 & $ n = 10^4 $ & $ n = 10^5 $ \\
        \midrule
        \num{0.341344} & \num{0.341329} & \num{0.341334}\\
        \bottomrule
    \end{tabularx}
    
    正如例~\ref{exam:4.2.1} 中所说明的, 可以通过线性变换将 $ [a, b] $ 区间上的定积分化成 $ [0, 1] $ 区间上的定积分, 所以以上方法计算定积分方法带有普遍意义。
\end{example}

\begin{xiti}
    \item 设 $ \{ X_k \} $ 为独立随机变量序列, 且
    \begin{equation*}
        P \bigl( X_k = \pm \sqrt{\ln k} \bigr) = \frac{1}{2}, \ k = 1, 2, \dotsc.
    \end{equation*}
    证明 $ \{ X_k \} $ 服从大数定律.
    \item 设 $ \{ X_k \} $ 为独立随机变量序列, 且
    \begin{equation*}
        P \bigl( X_k = \pm 2^k \bigr) = \frac{1}{2^{2k+1}}, \ P \bigl( X_k = 0 \bigr) = 1 - \frac{1}{2^{2k}}, \ k = 1, 2, \dotsc .
    \end{equation*}
    证明 $ \{ X_k \} $ 服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立随机变量序列, 且 $ P \bigl( X_1 = 0 \bigr) = 1 $,
    \begin{equation*}
        P \bigl( X_n = \pm \sqrt{n} \bigr) = \frac{1}{n}, \ P \bigl( X_n = 0 \bigr) = 1 - \frac{2}{n}, \ n = 2, 3, \dotsc .
    \end{equation*}
    证明 $ \{ X_n \} $ 服从大数定律.
    \item 在伯努利试验中, 事件 $ A $ 出现的概率为 $ p $, 令
    \begin{equation*}
        X+n = 
        \begin{cases}
            1, & \text{若在第} \ n \ \text{次及第} \ n+1 \ \text{次试验中} \ A \ \text{出现}\\
            0, & \text{其他}.
        \end{cases}
    \end{equation*}
    证明 $ \{ X_n \} $ 服从大数定律.
    \item  设 $ \{ X_n \} $ 为独立的随机变量序列, 且
    \begin{equation*}
        P \bigl( X_n = 1 \bigr) = p_n, \ P \bigl( X_n = 0 \bigr) = 1 - p_n.
    \end{equation*}
    证明 $ \{ X_n \} $ 服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其共同的分布函数为
    \begin{equation*}
        F (x) = \frac{1}{2} + \frac{1}{\pi} \arctan \frac{a}{x}, \ -\infty < x < +\infty 
    \end{equation*}
    试问: 辛钦大数定律对此随机变量序列是否适用?
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其共同分布为
    \begin{equation*}
        P \left( X_n = \frac{2^k}{k^2} \right) = \frac{1}{2^k}, \ k = 1, 2, \dotsc .
    \end{equation*}
    试问 $ \{ X_n \} $ 是否服从大数定律?
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其共同分布为
    \begin{equation*}
        P \bigl( X_n = k \bigr) = \frac{c}{k^2 \cdot \log^2 k}, \ k = 2, 3, \dotsc .
    \end{equation*}
    其中
    \begin{equation*}
        c = \left( \sum_{k = 2}^{+\infty} \frac{1}{k^2 \cdot \log^2 k} \right)^{-1},
    \end{equation*}
    试同 $ \{ X_n \} $ 是否服从大数定律?
    \item 设 $ \{ X_n \} $ 为独立的随机变量序列, 其中 $ X_n $ 服从参数为 $ \sqrt{n} $ 的泊松分布, 试问 $ \{ X_n \} $ 是否服从大数定律?
    \item 设 $ \{ X_n \} $ 为独立的随机变量序列, 每个 $ X_n $ 的方差 $ \sigma^2 $ 有限, 证明: 若
    \begin{equation*}
        \frac{\sigma_n^2}{n} \to 0, \ n \to +\infty.
    \end{equation*}
    则 $ \{ X_n \} $ 服从大数定律.
    \item (伯恩斯组大数定律) 设 $ \{ X_n \} $ 是方差有界的随机变量序列, 且当 $ \lvert k - l \rvert \to +\infty $ 时, 一致地有 $ Cov \bigl( X_k, X_l \bigr) \to 0 $, 证明 $ \{ X_n \} $ 服从大数定律.
    \item (格涅坚科大数定律) 设 $ \{ X_n \} $ 是随机变量序列, 若记
    \begin{equation*}
        Y_n = \frac{1}{n} \sum_{i=1}^n X_i, \ a_n = \frac{1}{n} \sum_{i=1}^n E (x_i).
    \end{equation*}
    则 $ \{ X_n \} $ 服从大数定律的充要条件是
    \begin{equation*}
        \lim_{n \to +\infty} E \left( \frac{( Y_n - a_n )^2}{1 + ( Y_n - a_n )^2} \right) = 0.
    \end{equation*}
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 方差存在.
    又设 $ \sum_{n=1}^{+\infty} a_n $ 为绝对收敛级数.
    令 $ Y = \sum_{i=1}^n X_i $, 证明 $ \{ a_n Y_n \} $服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 方差存在, 令 $ Y = \sum_{i=1}^n X_i $. 又设 $ \{ a_n \} $ 为一列常数, 如果存在常数 $ c > 0 $, 使得对一一切 $ n $ 有 $ \lvert n a_n \rvert \leq c $, 证明 $ \{ a_n Y_n \} $ 服从大数定律.
    \item 设 $ \{ X_n \} $ 为独立同分布的随机变量序列, 其方差有限, 且 $ X_n $ 不恒为常数.
    如果 $ S_n = \sum_{i=1}^n X_i $, 试证: 随机变量序列 $ \{ S_n \} $ 不服从大数定律.
    \item 分别用随机投点法和平均值法计算下列定积分:
    \begin{equation*}
        J_1 = \int_0^1 \frac{e^x - 1}{e - 1} \dd x, \ J_2 = \int_{-1}^1 \ee^x \dd x.
    \end{equation*}
\end{xiti}

\subsection{随机变量序列的两种收敛性}

随机变量序列的收敛性有多种, 其中常用的是两种: 依概率收敛和按分布收敛.
前面叙述的大数定律涉及的是一种依概率收敛, 后面叙述的中心极限定理将涉及按分布收敛.
这些极限定理不仅是概率论研究的中心议题, 而且在数理统计中有广泛的应用.
本节将给出这两种收敛性的定义及其有关性质, 读者应从中吸收其思考问题的方法.

\subsubsection{依概率收敛}

首先由随机变量序列 $ \{ X_n \} $ 服从``大数定律''的讨论启发我们引进如下定义.

\begin{definition}{依概率收敛}{4.3.1}
    设 $ \{ Y_n \} $ 为一随机变量序列, $ Y $ 为一随机变量.
    如果对任意的 $ \varepsilon > c $, 有
    \begin{equation}\label{eq:4.3.1}
        \lim_{n \to +\infty} P \bigl( \bigr\lvert Y_n - Y \bigr\rvert < \varepsilon \bigr) = 1,
    \end{equation}
    则称 $ \{ Y_n \} $ \textbf{依概率收敛}\index{收敛!依概率收敛} 于 $ Y $, 记作 $ Y_n \stackrel{P}{\to} Y $.
\end{definition}

前面讨论的独立同分布随机变量序列 $ \{ X_n \} $ 服从大数定律是上述依概率收敛的特殊情况, 这只要构造另一个随机变量序列 $ \{ Y_n \} $, 其中
\begin{equation*}
    Y_n = \frac{1}{n} \sum_{i=1}^n X_n, \quad Y = \frac{1}{n} \sum_{i=1}^n E \bigl( Y_i \bigr) = \mu,
\end{equation*}
就可看出, $ X_n $ 服从大数定律等价于 $ Y_n \stackrel{P}{\to} \mu $.
如今的依概率收敛是把原收敛于一个常数 $ \mu $ 推广到收敛于一个随机变量场合.

\begin{theorem}{}{4.3.1}
    设 $ \{ X_n \} $, $ \{ Y_n \} $ 是两个随机变量序列, $ a $, $ b $ 是两个常数.
    如果
    \begin{equation*}
        X_n \stackrel{P}{\to} a, \quad Y_n \stackrel{P}{\to} b,
    \end{equation*}
    则有
    \begin{enumerate}
        \item $ X_n \pm Y_n \stackrel{P}{\to} a \pm b $,
        \item $ X_n \times Y_n \stackrel{P}{\to} a \times b $,
        \item $ X_n \div Y_n \stackrel{P}{\to} a \div b (b \neq 0) $.
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item\label{thm:4.3.1.1} 因为
        \begin{equation*}
            \bigl\{ \bigl\lvert \bigl( X_n + Y_n \bigr) - ( a + b ) \bigr\rvert \geq \varepsilon \bigr\} \subset \biggl\{ \biggl( \bigl\lvert X_n - a \bigr\rvert \geq \frac{\varepsilon}{2} \biggr) \cup \biggl( \bigl\lvert Y_n - b \bigr\rvert \geq \frac{\varepsilon}{2} \biggr) \biggr\},
        \end{equation*}
        所以
        \begin{equation*}
            0 \leq P \bigl( \big\lvert \bigl( X_n + Y_n \bigr) - ( a + b ) \bigr\rvert \geq \varepsilon \bigr)
            \leq P \biggl( \bigl\lvert X_n - a \bigr\rvert \geq \frac{\varepsilon}{2} \biggr) + P \biggl( \bigl\lvert Y_n - b \bigr\rvert \geq \frac{\varepsilon}{2} \biggr) \to 0 \ ( n \to +\infty ).
        \end{equation*}
        即
        \begin{equation*}
            P \bigl( \bigl\lvert \bigl( X_n + Y_n ) - ( a + b ) \bigr\rvert < \varepsilon \bigr) \to 1 \ ( n \to +\infty ),
        \end{equation*}
        由此得 $ X_n + Y_n \stackrel{P}{\to} a + b $.
        类似可证 $ X_n - Y_n \stackrel{P}{\to} a - b $.
        \item\label{thm:4.3.1.2} 为了证明 $ X_n \times Y_n \stackrel{P}{\to} a \times b $, 我们分几步进行:
        \begin{enumerate}
            \item 若 $ X_n \stackrel{P}{\to} 0 $, 则有 $ X_n^2 \stackrel{P}{\to} 0 $.
            这是因为对任意 $ \varepsilon > 0 $, 有
            \begin{equation*}
                P \bigl( \bigl\lvert X_n^2 \bigr\rvert \geq \varepsilon \bigr) = P \bigl( \bigl\lvert X_n \bigr\rvert \geq \sqrt{\varepsilon} \bigr) \to 0, \ n \to + \infty.
            \end{equation*}
            \item 若 $ X_n \stackrel{P}{\to} a $, 则有 $ cX_n \stackrel{P}{\to} ca $. 这是因为在 $ c \neq 0 $ 时, 有
            \begin{equation*}
                P \bigl( \bigl\lvert c X_n - ca \bigr\rvert \geq \varepsilon \bigr) = P \bigl( \bigl\lvert X_n - a \bigr\rvert \geq \varepsilon/\lvert c \rvert \bigr) \to 0, \ n \to +\infty,
            \end{equation*}
            而当 $ c = 0$ 时, 结论显然成立.
            \item\label{thm:4.3.1.2.3} 若 $ X_n \stackrel{P}{\to} a $, 则有 $ X_n^2 \stackrel{P}{\to} a^2 $.
            这是因为有以下一系列结论:
            \begin{gather*}
                X_n - a \stackrel{P}{\to} 0, \ \bigl( X_n - a \bigr)^2 \stackrel{P}{\to} 0, \ 2a \bigl( X_n - a \bigr) \stackrel{P}{\to} 0,\\
                \bigl( X_n - a \bigr)^2 + 2a \bigl( X_n - a \bigr) = X_n^2 - a^2 \stackrel{P}{\to} 0, \ \text{即} \ X_n^2 \stackrel{P}{\to} a^2.
            \end{gather*}
            \item 由 \ref{thm:4.3.1.2.3} 及 \ref{thm:4.3.1.1} 知
            \begin{equation*}
                X_n^2 \stackrel{P}{\to} a^2, \ Y_n^2 \stackrel{P}{\to} b^2, \ \bigl( X_n + Y_n \bigr)^2 \stackrel{P}{\to} ( a + b )^2.
            \end{equation*}
            从而有
            \begin{align*}
                X_n \times Y_n & = \frac{1}{2} \bigl[ \bigl( X_n + y_n \bigr)^2 - X_n^2 - Y_n^2 \bigr]\\
                & \stackrel{P}{\to} \frac{1}{2} [ ( a + b )^2 - a^2 - b^2 ] = ab.
            \end{align*}
        \end{enumerate}
        \item 为了证明 $ X_n / Y_n \stackrel{P}{\to} a/b $, 我们先证: $ 1 / Y_n \stackrel{P}{\to} 1 / b $.
        这是因为对任意 $ \varepsilon > 0 $, 有
        \begin{align*}
            P \biggl( \biggl\lvert \frac{1}{Y_n} - \frac{1}{b} \biggr\rvert \geq \varepsilon \biggr)
            ={} & P \biggl( \biggl\lvert \frac{Y_n - b}{Y_n b} \biggr\rvert \geq \varepsilon \biggr)\\
            ={} & P \biggl( \biggl\lvert \frac{Y_n - b}{b^2 + b ( Y_n - b )} \biggr\rvert \geq \varepsilon, \bigl\lvert Y_n - b \bigr\rvert < \varepsilon \biggr)\\
            & + P \biggl( \biggl\lvert \frac{Y_n - b}{b^2 + b ( Y_n - b )} \biggr\rvert \geq \varepsilon, \bigl\lvert Y_n - b \bigr\rvert \geq \varepsilon \biggr)\\
            ={} & P \biggl( \frac{\lvert Y_n - b \rvert}{b^2 - \varepsilon \lvert b \rvert} \geq \varepsilon \biggr)
            + P \bigl( \bigl\lvert Y_n + b \bigr\rvert \geq \varepsilon \bigr)\\
            ={} & P \bigl( \bigl\lvert Y_n - b \bigr\rvert \geq \bigl( b^2 - \varepsilon \lvert b \rvert \bigr) \varepsilon \bigr)
            + P \bigl( \bigl\lvert Y_n - b \bigr\rvert \geq \varepsilon \bigr)\\
            \to {} & 0, \ n \to +\infty.
        \end{align*}
        这就证明了 $ 1 / Y_n \stackrel{P}{\to} 1 / b $, 再与 $ X_n \stackrel{P}{\to} a $ 结合, 利用 \ref{thm:4.3.1.2} 即得 $ X_n / Y_n \stackrel{P}{\to} a / b $.
        这就完成了全部证明.
    \end{enumerate}
\end{proof}

由此定理可以看出, 随机变量序列在概率意义下的极限 (即依概率收敛于常数 $ a $) 在四则运算下仍然成立.
这与数学分析中的数列极限十分类似.

\subsubsection{按分布收敏、弱收敛}

我们知道分布函数全面描述了随机变量的统计规律， 因此讨论一个分布函数序列 $ \{ F_n (x) \} $ 收敛到一个极限分布函数 $ F (x) $ 是有实际意义的.
现在的问题是: 如何来定义 $ \{ F_n (x) \} $ 的收敛性呢?
很自然地, 由于 $ \{ F_n (x) \} $ 是实变量函数序列, 我们的一个猜想是: 对所有的 $ x $, 要求 $ F_n (x) \to F (x) \ ( n \to +\infty ) $ 都成立, 也即数学分析中的点点收敛.
然而遗憾的是, 以下例子告诉我们这个要求过严了.

\begin{example}\label{exam:4.3.1}
    设 $ \{ X_n \} $ 服从如下的退化分布
    \begin{equation*}
        P \biggl( X_n = \frac{1}{n} \biggr) = 1, \quad n = 1, 2, \dotsc,
    \end{equation*}
    若记它们的分布函数分别为 $ F_x (x) $, 则
    \begin{equation*}
        F_n ( x ) =
        \begin{cases}
            0, & x < 1/n,\\
            1, & x \geq 1/n.
        \end{cases}
    \end{equation*}
    因为 $ F_n (x) $ 是在点 $ x=1 $ 处有跳跃, 所以当 $ n \to +\infty $ 时, 跳跃点位置趋于0, 于是我们很自然地认为 $ \{ F_n (x) \} $ 应该收敛于点 $ x=0 $处的退化分布, 即
    \begin{equation*}
        F (x) =
        \begin{cases}
            0, & x < 0,\\
            1, & x \geq 0.
        \end{cases}
    \end{equation*}

    但是, 对任意的 $ n $, 有 $ F_n (0) = 0 $, 而 $ F (0) = 1 $, 所以
    \begin{equation*}
        \lim_{n \to +\infty} F_n (0) = 0 \neq 1 = F (0).
    \end{equation*}
\end{example}

从这个例子我们得到启示:
\begin{enumerate}
    \item 对分布函数序列 $ \{ F_n (x) \} $ 而言, 要求其点点收敛到一个极限分布函数 $ F_n (x) $ 是太苛刻了, 以上这么简单的一个例于都无法达到要求.
    甚至在点点收效这个苛刻的要求下, $ \{ F_n (x) \} $ 的极限函数
    \begin{equation*}
        g (x) =
        \begin{cases}
            0, & x \leq 0,\\
            1, & x > 0,
        \end{cases}
    \end{equation*}
    不满足右连续性，即 $ g (x) $ 不是一个分布函数.
    \item 如何把点点收效这要求减``弱''一些呢?
    从这个例子又可以发现: 收敛关系不成立的点 $ x=0 $, 恰好是 $ F (x) $ 的间断点.
    这就启示我们, 可以撤开这些间断点而只考虑 $ F (x) $ 的连续点.
    这就是以下给出的关于分布函数列的弱收敛定义.
\end{enumerate}

\begin{definition}{}{4.3.2}
    设随机变量 $ X, X_1,  X_2, \dotsc $  的分布函数分别为 $ F (x), F_1 (x), F_2 (x), \dotsc $.
    若对 $ F (x) $ 的任一连续点 $x$, 都有
    \begin{equation}\label{eq:4.3.2}
        \lim_{n \to +\infty} F_n (x) = F (x),
    \end{equation}
    则称 $ \{ F_n (x) \} $ \textbf{弱收敛}\index{收敛!弱收敛}于 $ F (x) $, 记作
    \begin{equation}\label{eq:4.3.3}
        F_n (x) \stackrel{W}{\to} F (x).
    \end{equation}
    也称 $ \{ X_n \} $ \textbf{按分布收敛}\index{收敛!按分布收敛}于 $ X $, 记作
    \begin{equation}\label{eq:4.3.4}
        X_n \stackrel{L}{\to} X.
    \end{equation}
\end{definition}

以上定义的``弱收敛''是自然的, 因为它比在每一点上都收敛的要求的确``弱''了些.
若 $ F (x) $ 是直线上的连续函数, 则弱收敛就是点点收敛.

注意, 在上述定义中, 对分布函数序列 $ \{ F_n (x) \} $ 称为弱收敛, 而对其随机变量序列 $ \{ X_n \} $ 则称为按分布收敛, 这是在两种不同场合给出的两个不同名称, 但其本质含义是一样的, 都要求在 $ F (x) $ 的连续点上有 \eqref{eq:4.3.2}.

下面的定理说明依概率收敛是一种比按分布收敛更强的收敛性.

\begin{theorem}{}{4.3.2}
    \begin{equation*}
        X_n \stackrel{P}{\to} X \Rightarrow X_n \stackrel{L}{\to} X.
    \end{equation*}
\end{theorem}

\begin{proof}
    设随机变量 $ X, X_1,  X_2, \dotsc $  的分布函数分别为 $ F (x), F_1 (x), F_2 (x), \dotsc $.
    为证 $ X_n \stackrel{L}{\to} X $, 相当于证 $ F_n (x) \stackrel{W}{\to} F (x) $, 所以只须证: 对所有的 $ x $, 有
    \begin{equation}\label{eq:4.3.5}
        F ( x - 0 ) \leq \varliminf_{n \to +\infty} F_n (x) \leq \varlimsup_{n \to +\infty} F_x (x) \leq F ( x + 0 ).
    \end{equation}
    因为若上式成立, 则当 $ x $ 是 $ F (x) $ 的连续点时, 有 $ F (x-0) =F (x+0) $, 由此即可得 $ F_n (x) \stackrel{W}{\to} F (x) $.
    
    为证 \eqref{eq:4.3.5}, 先令 $ x' < x $, 则
    \begin{equation*}
        \{ X \leq x' \} = \{ X_n \leq x, X \leq x' \} \cup \{ X_n > x, X \leq x' \} \subset \{ X_n \leq x \} \cup \{ \bigl\lvert X_n - X \bigr\rvert \geq x - x' \},
    \end{equation*}
    从而有
    \begin{equation*}
        F (x') \leq F_n (x) + P \bigl( \bigl\lvert X_n - X \bigr\rvert \geq x - x' \bigr).
    \end{equation*}
    由 $ x_n \stackrel{P}{\to} x $, 得 $ P ( \lvert X_n - X \rvert \geq x - x' ) \to 0 $, $ (n \to +\infty) $.
    所以有
    \begin{equation*}
        F (x') \leq \varliminf_{n \to +\infty} F_n (x).
    \end{equation*}
    再令 $ x' \to x $, 即得
    \begin{equation*}
        F (x-0) \leq \varliminf_{n \to +\infty} F_n (x).
    \end{equation*}
    
    同理可证，当 $ x'' > x $ 时, 有
    \begin{equation*}
        \varlimsup_{n \to +\infty} F_n (x) \leq F (x'').
    \end{equation*}
    令 $ x'' \to x $, 即得
    \begin{equation*}
        \varlimsup_{n \to +\infty} F_n (x) \leq F (x + 0).
    \end{equation*}
    这就证明了定理.
\end{proof}

注意, 以上定理的逆命题不成立, 即由按分布收敛无法推出依概率收敛, 见下例.

\begin{example}\label{exam:4.3.2}
    设 $ X $的分布列为
    \begin{equation*}
        P ( X = -1 ) = \frac{1}{2}, \quad P ( X = 1) = \frac{1}{2}.
    \end{equation*}
    令 $ X_n = -X $, 则 $ X_n $ 与 $ X $ 同分布, 即 $ X_n $ 与 $ X $ 有相同的分布函数, 故 $ X_n \stackrel{L}{\to} X $.

    但对任意的 $ 0 < \varepsilon < 2 $, 有
    \begin{equation*}
        P \bigl( \bigl\lvert X_n - X \bigr\rvert \geq \varepsilon \bigr) = P ( 2 \lvert X \rvert \geq \varepsilon ) = 1 \nrightarrow 0.
    \end{equation*}
    即 $ X_n $ 不是依概率收敛于 $ X $.
\end{example}

以上例子说明: 一般按分布收敛与依概率收敛是不等价的.
而下面的定理则说明: 当极限随机变量为常数 (服从退化分布) 时, 按分布收敛与依概率收敛是等价的.

\begin{theorem}{}{4.3.3}
    若 $ c $ 为常数, 则 $ X_n \stackrel{P}{\to} c $ 的充要条件是: $ X_n \stackrel{L}{\to} c $.
\end{theorem}

\begin{proof}
    必要性已由定理~\ref{thm:4.3.2} 给出, 下证充分性.
    记 $ X_n $ 的分布函数为 $ F (x) $, $ n = 1, 2, \dotsc $, 因为常数 $ c $ 的分布函数 (退化分布) 为
    \begin{equation*}
        F (x) =
        \begin{cases}
            0, & x < c,\\
            1, & x \geq c.
        \end{cases}
    \end{equation*}
    所以对任意的 $ \varepsilon > 0 $, 有
    \begin{align*}
        P \big( \big\lvert X_n - c \bigr\rvert \geq \varepsilon \bigr)
        & = P \bigl( X_n \geq c + \varepsilon \bigr) + P \bigl( X_n \leq c - \varepsilon \bigr)\\
        & \leq P \bigl( X_n > c + \varepsilon / 2 \bigr) + P \bigl( X_n \leq c - \varepsilon \bigr)\\
        & = 1 - F_n ( c + \varepsilon / 2 ) + F_n ( c - \varepsilon ).
    \end{align*}

    由于 $ x = c + \varepsilon / 2 $ 和 $ x = c - \varepsilon $ 均为 $ F (x) $ 的连续点, 且 $ F_n (x) \stackrel{W}{\to} F (x) $, 所以当 $ n \to +\infty $ 时, 有
    \begin{equation*}
        F_n ( c + \varepsilon / 2 ) \to F ( c + \varepsilon / 2 ) = 1, \quad F_n ( c - \varepsilon) \to F ( c - \varepsilon ) = 0.
    \end{equation*}
    由此得
    \begin{equation*}
        P \bigl( \bigl\lvert X_n - c \bigr\rvert \geq \varepsilon \bigr) \to 0. 
    \end{equation*}
    即 $ X_n \stackrel{P}{\to} X $.
    定理证毕.
\end{proof}

\subsubsection{判断弱收敛的方法}

分布函数列的弱收敛是一个很有用的概念, 它可帮助我们寻求极限分布.
但判别一个分布函数列是否弱收敛于某个分布函数, 有时是很麻烦的, 这时我们就可利用特征函数这一工具, 为此要研究: 分布函数序列的弱收敛性与相应的特征函数序列的点点收敛性有什么关系?
下面的定理指出这是等价的.

\begin{theorem}{}{4.3.4}
    分布函数序列 $ \{ F_n (x) \} $ 弱收敛于分布函数 $ F (x) $ 的充要条件是 $ \{ F_n (x) \} $ 的特征函数序列 $ \varphi_n (t) $ 收敛于 $ F (x) $ 的特征函数 $ \varphi (t) $.
\end{theorem}

这个定理的证明只涉及数学分析的一些结果, 且证明比较冗长 (参阅文献
[1]), 在此就不介绍了.
通常把以上定理称为特征函数的连续性定理, 因为它表明分布函数与特征函数的一一对应关系有连续性.

\begin{example}\label{exam:4.3.3}
    若 $ X_\lambda $ 服从参数为 $ \lambda $ 的泊松分布, 证明:
    \begin{equation*}
        \lim_{\lambda \to +\infty} \left( \frac{X_\lambda - \lambda}{\sqrt{\lambda}} \leq x \right) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x \exp \left( - \frac{t^2}{2} \right) \dd t.
    \end{equation*}
\end{example}

\begin{proof}
    已知 $ X_\lambda $ 的特征函数为 $ \varphi_\lambda (t) = \exp \bigl( \lambda ( \ee^{it} - 1 ) \bigr) $, 故 $ Y_n = \bigl( X_n - \lambda \bigr) / \sqrt{\lambda} $ 的特征函数为
    \begin{equation*}
        g_\lambda (t) = \varphi_\lambda \left( \frac{t}{\sqrt{\lambda}} \right) \exp \left( -i \sqrt{\lambda} t \right) = \exp \left( \lambda \left( \ee^{i t / \sqrt{\lambda}} - 1 \right) - i \sqrt{\lambda} t \right).
    \end{equation*}
    对任意的 $ t $, 有
    \begin{equation*}
        \exp \left( i \frac{t}{\sqrt{\lambda}} \right) = 1 + \frac{it}{\sqrt{\lambda}} - \frac{t^2}{2!\lambda} + o \left( \frac{1}{\lambda} \right),
    \end{equation*}
    于是
    \begin{equation*}
        \lambda \left( \ee^{it / \sqrt{\lambda}} - 1 \right) - i \sqrt{\lambda} t = - \frac{t^2}{2} + \lambda \cdot o \left( \frac{1}{\lambda} \right) \to - \frac{t^2}{2}, \ n \to +\infty.
    \end{equation*}
    从而有
    \begin{equation*}
        \lim_{\lambda \to +\infty} g_\lambda (t) = \ee^{-t^2 / 2},
    \end{equation*}
    而 $ \ee^{-t^2 / 2} $ 正是标准正态分布 $ N (0, 1) $ 的特征函数, 由定理~\ref{thm:4.3.4} 即知结论成立.
\end{proof}

最后, 我们利用以上的一些结论来证明 \ref{sec:4.2} 节中的辛钦大数定律.

\textbf{辛软大数定律的证明}:
设 $ \{ X_n \} $ 独立同分布, 且 $ E (X_n) = a, i=1, 2, \dotsc $.
现在要证明
\begin{equation*}
    \frac{1}{n} \sum_{k=1}^n X_k \stackrel{P}{\to} a, \ n \to +\infty.
\end{equation*}
为此记
\begin{equation*}
    Y_n = \frac{1}{n} \sum_{k=1}^n X_k.
\end{equation*}
由定理~\ref{thm:4.3.3} 知, 只须证 $ Y_n \stackrel{L}{\to} a $.
又由定理~\ref{thm:4.3.4} 知, 只须证 $ \varphi_Y (t) \to \ee^{-iat} $.

因为 $ \{ X_n \} $ 同分布, 所以它们有相同的特征函数, 记这个特征函数为 $ \varphi (t) $.
又因为 $ \varphi(0) / i = E ( X_i ) = a $, 从而 $ \varphi (t) $ 在0点展开式为
\begin{equation*}
    \varphi (t) = \varphi (0) + \varphi' (0) t + o (t) = 1 + iat + o (t).
\end{equation*}
再由 $ \{ X_n \} $ 的独立性知 $ Y_n $ 的特征函数为
\begin{equation*}
    \varphi_{Y_n} (t) = \bigl( \varphi ( t / n) \bigr)^n = \bigl( 1 + iat/n + o (1/n) \bigr)^n.
\end{equation*}
对任意的 $ t $ 有
\begin{equation*}
    \lim_{n \to +\infty} \bigl( \varphi ( t / n) \bigr)^n = \lim_{n \to +\infty} \bigl( 1 + iat/n + o (1/n) \bigr)^n = \ee^{iat}.
\end{equation*}
而 $ \ee^{iat} $ 正是退化分布的特征函数, 由此证得了 $ Y_n \stackrel{L}{\to} a $.
至此定理得证.

\begin{xiti}
    \item 如果 $ X_n \stackrel{P}{\to} X $, 且 $ X_n \stackrel{P}{\to} Y $. 试证: $ P ( X = Y ) = 1 $.
    \item 如果 $ X_n \stackrel{P}{\to} X $, $ Y_n \stackrel{P}{\to} Y $. 试证:
    \begin{enumerate}
        \item $ X_n + Y_n \stackrel{P}{\to} X + Y $;
        \item $ X_n \times Y_n \stackrel{P}{\to} X \times Y $.
    \end{enumerate}
    \item 如果 $ X_n \stackrel{P}{\to} X $, $ g (x) $ 是直线上的连续函数, 试证: $ g ( X_n ) \stackrel{P}{\to} g (X) $.
    \item 如果 $ X_n \stackrel{P}{\to} a $, 则对任意常数 $ c $, 有
    \begin{equation*}
        c X_n \stackrel{P}{\to} ca.
    \end{equation*}
    \item 试证: $ X_n \stackrel{P}{\to} X $ 的充要条件为: $ n \to +\infty $ 时, 有
    \begin{equation*}
        E \left( \frac{\lvert X_n - X \rvert}{1 + \lvert X_n - X \rvert} \right) \to 0.
    \end{equation*}
    \item 设 $ D (x) $ 为退化分布:
    \begin{equation*}
        D (x) =
        \begin{cases}
            0, & x < 0,\\
            1, & x \geq 0.
        \end{cases}
    \end{equation*}
    试问下列分布函数列的极限函数是否仍是分布函数? (其中 $ n = 1, 2, \dotsc $.)
    \begin{enumerate}
        \item $ \{ D ( x + n ) \} $,
        \item $ \{ D ( x + 1/n ) \} $,
        \item $ \{ D ( x - 1/n ) \} $.
    \end{enumerate}
    \item 设分布函数列 $ \{ F_n (x) \} $ 弱收敛于连续的分布函数 $ F (x) $, 试证: $ \{ F_n (x) \} $ 在 $ ( -\infty, +\infty ) $ 上一致收敛于分布函数 $ F (x) $.
    \item 利用特征函数方法证明如下的泊松定理： 设有一列二项分布 $ \{ b ( k, n, p_n ) \} $, 若 $ \lim_{n \to +\infty} n p_n = \lambda > 0 $, 则
    \begin{equation*}
        \lim_{n \to +\infty} b ( k, n, p_n ) = \frac{\lambda^k}{k!} \ee^{\lambda}, \ k = 0, 1, 2, \dotsc.
    \end{equation*}
    \item 如果 $ X_n \stackrel{L}{\to} X $, 且数列 $ a_n \to a $, $ b_n \to b $. 试证: $ a_n X_n + b_n \stackrel{L}{\to} a X + b $.
    \item 如果 $ X_n \stackrel{L}{\to} X $, $ Y_n \stackrel{P}{\to} a $, 试证: $ X_n + Y_n \stackrel{L}{\to} X + a $.
    \item 如果 $ X_n \stackrel{L}{\to} X $, $ Y_n \stackrel{P}{\to} 0 $, 试证: $ X_n Y_n \stackrel{P}{\to} 0 $.
    \item 如果 $ X_n \stackrel{L}{\to} X $, $ Y_n \stackrel{P}{\to} a $, 且 $ Y_n \neq 0 $, 常数 $ a \neq 0 $, 试证: $ X_n / Y_n \stackrel{L}{\to} X/a $.
    \item 设随机变量 $ X_n $ 服从柯西分布, 其密度函数为
    \begin{equation*}
        p_n (x) = \frac{n}{\pi (1 + n^2 x^2)}, \ -\infty < x < +\infty.
    \end{equation*}
    试证 $ X_n \stackrel{P}{\to} 0 $.
    \item 设随机变量序列 $ \{ X_n \} $ 独立同分布, 其密度函数为
    \begin{equation*}
        p (x) =
        \begin{cases}
            1 / \beta, & 0 < x < \beta,\\
            0, & \text{其他}.
        \end{cases}
    \end{equation*}
    其中常数 $ \beta > 0 $. 令 $ Y_n = \max ( X_1, X_2, \dotsc, X_n ) $, 试证: $ Y_n \stackrel{P}{\to} \beta $.
    \item 设随机变量序列 $ \{ X_n \} $ 独立同分布, 其密度函数为
    \begin{equation*}
        p (x) =
        \begin{cases}
            \ee^{- ( x - a )}, & x \geq a,\\
            0, & x < a.
        \end{cases}
    \end{equation*}
    令 $ Y_n = \min ( X_1, X_2, \dotsc, X_n ) $, 试证: $ Y_n \stackrel{P}{\to} a $.
    \item 设分布函数列 $ \{ F_n (x) \} $ 弱收敛于分布函数 $ F (x) $, 且 $ F_n (x) $ 和 $ F (x) $ 都是连续、严格单调函数, 又设 $ \xi $ 服从 $ ( 0, 1 ) $ 上的均匀分布, 试证: $ F_n^{-1} ( \xi ) \stackrel{P}{\to} F^{-1} ( \xi ) $.
    \item 设随机变量序列 $ \{ X_n \} $ 独立同分布, 数学期望、方差均存在, 且 $ E ( x_n ) = \mu $, 试证:
    \begin{equation*}
        \frac{2}{n ( n + 1 )} \sum_{k = 1}^n k \cdot X_k \stackrel{P}{\to} \mu.
    \end{equation*}
    \item 设随机变量序列 $ \{ X_n \} $ 独立同分布, 数学期望、方差均存在, 且
    \begin{equation*}
        E \bigl( X_n \bigr) = 0, \ Var \bigl( X_n \bigr) = \sigma^2.
    \end{equation*}
    试证：
    \begin{equation*}
        \frac{1}{n} \sum_{k = 1}^n X_k^2 \stackrel{P}{\to} \sigma^2.
    \end{equation*}
    \item 设随机变量序列 $ \{ X_n \} $ 独立同分布, 且 $ Var (X_n) = \sigma^2 $ 存在, 令
    \begin{equation*}
        \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i, \ S_n^2 = \frac{1}{n} \sum_{i=1}^n \bigl( X_i - \bar{X} \bigr)^2.
    \end{equation*}
    试证: $ S_n^2 \stackrel{P}{\to} \sigma^2 $.
    \item 设随机变量 $ X \sim Ga ( a, \lambda ) $, 证明: 当 $ a \to +\infty $ 时, 随机变量 $ ( \lambda X - a )/\sqrt{a} $ 按分布收敛于标准正态变量.
\end{xiti}


\section{中心极限定理}

\subsection{独立随机变量和}

大数定律讨论的是多个随机变量的平均 $ \frac{1}{n} \sum_{i=1}^n X_i $ 的渐近性质.
现在我们来讨论独立随机变量和
\begin{equation*}
    Y_n = \sum_{i=1}^n X_i
\end{equation*}
的极限分布.
以下我们先给出一个独立随机变量和的例子.

\begin{example}\label{exam:4.4.1}
    误差分析是人们经常遇到且感兴趣的随机变量, 大量的研究表明, 误差的产生是由大量微小的相互独立的随机因素叠加而成的, 譬如一位操作者在机床加工机械轴, 使其直径符合规定要求, 但加工后的机械轴与规定要求总有一定的误差, 这是因为在加工时受到一些随机因素的影响, 它们是
    \begin{itemize}
        \item 在机床方面有机床振动与转速的影响;
        \item 在刀具方面有装配与磨损的影响;
        \item 在材料方面有钢材的成分、产地的影响;
        \item 在操作者方面有注意力集中程度、当天的情绪的影响;
        \item 在测量方面有量具误差、测量技术的影响;
        \item 在环境方面有车间的温度、湿度、照明、工作电压的影响:
        \item 在具体场合还可列出许多其他影响因素.
    \end{itemize}
    由于这些因素很多, 每个因素对加工精度的影响都是很微小的, 每个因素的出现都是人们无法控制的、是随机的、时有时无、时大时小、时正时负.
    这些因素的综合影响最后使每个加工轴的直径产生误差, 若将这个误差记为 $ Y_n $, 那么 $ Y_n $ 是随机变量, 且可以将 $ Y_n $ 看作很多微小的随机波动 $ X_1, X_2, \dotsc, X_n $ 之和, 即
    \begin{equation*}
        Y_n = X_1 + X_2 + \dotsb X_n,
    \end{equation*}
    这里 $ n $ 是很大的, 人们关心的是当 $ n \to +\infty $ 时, ``$ Y_n $ 的分布是什么?''
\end{example}

当然, 我们可以用卷积公式去计算 $ Y_n $ 的分布, 但是这样的计算是相当复杂的、不易实现的.
有的可写出 $ Y_n $ 的分布, 由于其形式复杂而无法使用, 这从下面例子可以看出这一点.

\begin{example}\label{exam:4.4.2}
    设 $ \{ X_n \} $ 为独立同分布随机变量序列, 其共同分布为区间 $ ( 0, 1 ) $ 上的均匀分布.
    记 $ Y_n = \sum_{i = 1}^n X_i $, $ p_n (y) $ 为 $ Y_n $ 的密度函数, 用卷积公式可以求出
    \begin{align*}
        p_1 ( y ) & =
        \begin{cases}
            1, & 0 < y < 1,\\
            0, & \text{其他}.
        \end{cases}\\
        p_2 ( y ) & =
        \begin{cases}
            y, & 0 < y < 1,\\
            2 - y, & 1 \leq y < 2,\\
            0, & \text{其他}.
        \end{cases}\\
        p_3 ( y ) & =
        \begin{cases}
            y^2 / 2, & 0 < y < 1,\\
            - ( y - 3 / 2 )^2 + 3 / 4, & 1 \leq y < 2,\\
            ( 3 - y )^2 / 2, & 2 \leq y < 3,\\
            0, \text{其他}.
        \end{cases}\\
        p_4 ( y ) & =
        \begin{cases}
            y^2 / 6, & 0 < y < 1,\\
            \bigl( y^3 - 4 ( y - 1 )^3 \bigr) / 6, & 1 \leq y < 2,\\
            \bigl( ( 4 - y )^3 - 4 ( 3 - y )^3 \bigr) / 6, & 2 \leq y < 3,\\
            ( 4 - y )^3 / 6, & 3 \leq y < 4,\\
            0, & \text{其他}.
        \end{cases}
    \end{align*}
    将 $ p_1 (y) $, $ p_2 (y) $, $ p_3 (y) $, $ p_4 (y) $ 表示在图~\ref{fig:4.4.1} 中.
    从图上我们可以看出: 随着 $ n $ 的增加, $ p_n ( y ) $ 的图形愈来愈光滑, 且愈来愈接近正态曲线.
\end{example}

\begin{figure}
    \centering
    % \begin{tikzpicture}[samples=100,>=stealth,every node/.style={scale=0.5}]
    %     \draw[->] (0,0) -- (4.2,0) node[right] {$y$};
    %     \draw[->] (0,0) -- (0,1.2) node[above] {$p(y)$};
    %     \draw (0,1) -- (1,1);
    %     \draw[semithick] (0,0) -- (1,1) -- (2,0);
    %     \draw[densely dashed,domain=0:1] plot(\x,{(\x)^2/2});
    %     \draw[dashed,domain=1.03:2] plot(\x,{-(\x-3/2)^2+3/4});
    %     \draw[dashed,domain=2.03:3] plot(\x,{(3-\x)^2/2});
    %     \draw[dashed,domain=0:1] plot(\x,{(\x)^2/6});
    %     \draw[dashed,domain=1.03:2] plot(\x,{((\x)^3-4*(\x-1)^3)/6});
    %     \draw[dashed,domain=2.03:3] plot(\x,{((4-\x)^3-4*(3-\x)^3)/6});
    %     \draw[densely dashed,domain=3.03:4] plot(\x,{(4-\x)^3/6});
    %     \draw[->] (0.82,1.2) node[above right=-1.5pt and -1.5pt] {$p_1(y)$} -- (0.7,1);
    %     \draw[->] (1.35,1) node[above right=-1.5pt and -1.5pt] {$p_2(y)$} -- (1.2,0.8);
    %     \draw[->] (1.85,0.9) node[above right=-1.5pt and -1.5pt] {$p_3(y)$} -- (1.7,0.7);
    %     \draw[->] (2.85,0.55) node[above right=-1.5pt and -1.5pt] {$p_4(y)$} -- (2.7,0.35);
    %     \foreach \i in {1,...,4} \draw[very thin] (\i,0)node[below]{\i}-- (\i,0.02);
    %     \foreach \i in {1/6,1/2,2/3,3/4,1} {\draw[very thin,font=\scriptsize] (0,\i) -- (0.04,\i) node[left] {\i};}
    %     \draw[densely dotted] (0,1/6) -- (1,1/6);
    %     \draw[densely dotted] (0,1/2) -- (1,1/2);
    %     \draw[densely dotted] (0,2/3) -- (1.8,2/3);
    %     \draw[densely dotted] (0,3/4) -- (1.26,3/4);
    % \end{tikzpicture}
    \includegraphics[width=0.9\linewidth]{figure/fig4-4-1.pdf}
    \caption{均匀分布的卷积}\label{fig:4.4.1}
\end{figure}

可以设想, 当 $ n = 100 $ 时, $ p_{100} (x) $ 的非零区城为 $ ( 0, 100 ) $, 若用卷积公式可以分 100 段求出 $ p_{100} ( x ) $ 的表达式, 它们分别是 99 次多项式.
如此复杂的形式即使求出 (当然没有人去求), 也无法使用.
这就迫使人们去寻求近似分布.
若记 $ Y_n $ 的分布函数为 $ F_n (x) $, 在弱收敛的含义下, 求出其极限分布 $ F (x) $, 那么当 $ n $ 很大时, 就可用 $ F(x) $ 作为 $ F_n (x) $ 的近似分布.

为了使寻求 $ Y_n $ 的极限分布有意义, 有必要先研究一下问题的提法.
在图~\ref{fig:4.4.1} 上可以看出: 当 $ n $ 增大时, $ p_n (y) $ 的中心右移, 且 $ p_n (y) $ 的方差增大.
这意味着当 $ n \to +\infty $ 时, $ Y_n $ 的分布中心会趋向 $ +\infty $, 其方差也趋向 $ +\infty $.
这种情况就没有什么意义了.
为了克服这个缺点, 在中心极限定理的研究中均对 $ Y_n $ 进行标准化
\begin{equation*}
    Y_n^* = \frac{Y_n - E (Y_n)}{\sqrt{Var ( Y_n )}}.
\end{equation*}
由于 $ E (Y_n) = 0 $, $ Var (Y_n) = 1 $, 这就有可能得出 $ Y_n $ 的极限分布为标准正态分布 $ N (0, 1) $.

中心极限定理就是研究独立随机变量和的极限分布为正态分布的问题.

\subsection{独立同分布下的中心极限定理}

\begin{theorem}{林德贝格-勒维中心极限定理}{4.4.1}
    设 $ \{ X_n \} $ 是独立同分布的随机变量序列, 且 $ E (X_n) = \mu $, $ Var (X_n)= \sigma^2 > 0 $.
    记
    \begin{equation*}
        Y_n^* = \frac{X_1 + X_2 + \dotsb + X_n - n \mu}{\sigma \sqrt{n}},
    \end{equation*}
    则对任意实数 $ y $, 有
    \begin{equation}\label{eq:4.4.1}
        \lim_{n \to +\infty} P ( Y_n ^* \leq y ) = \Phi (y) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^y \ee^{-t^2/2} \dd t.
    \end{equation}
\end{theorem}

\begin{proof}
    为证 \eqref{eq:4.4.1}, 只须证 $ \{ Y_n^* \} $ 的分布函数列弱收敛于标准正态分布.
    又由定理~\ref{thm:4.3.4}, 只须证 $ \{ Y_n^* \} $ 的特征函数列收敛于标准正态分布的特征函数.
    为此设 $ X_n - \mu $ 的特征函数为 $ \varphi (t) $, 则 $ \{ Y_n^* \} $ 的特征函数为
    \begin{equation*}
        \varphi_{Y_n^*} (t) = \Biggl( \varphi \biggl( \frac{t}{\sigma \sqrt{n}} \biggr) \Biggr)^n.
    \end{equation*}
    又因为 $ E ( X_n - \mu ) = 0 $, $ Var ( X_n - \mu ) = \sigma^2 $, 所以有
    \begin{equation*}
        \varphi' (0) = 0, \ \varphi'' (0) = - \sigma^2.
    \end{equation*}
    于是特征函数 $ \varphi (t) $ 有展开式
    \begin{align*}
        \varphi (t) & = \varphi (0) + \varphi' (0) t + \varphi'' (0) \frac{t^2}{2} + o (t^2)\\
        & = 1 - \frac{1}{2} \sigma^2 t^2 + o (t^2).
    \end{align*}
    从而有
    \begin{equation*}
        \lim_{n \to +\infty} \varphi_{Y_n^*} (t) = \lim_{n \to +\infty} \Biggl( 1 - \frac{t^2}{2n} + o \biggl( \frac{t^2}{n} \biggr) \Biggr)^n = \ee^{-t^2/n},
    \end{equation*}
    而 $ \ee^{-t^2/2} $正是 $ N (0,1) $ 分布的特征函数, 定理得证.
\end{proof}

定理~\ref{thm:4.4.1} 有广泛的应用, 它只假设 $ \{ X_n \} $ 独立同分布、方差存在, 不管原来的分布是什么, 只要 $ n $充分大, 就可以用正态分布去逼近.
以下给出一些林德贝格-勒维中心极限定理的应用例子.

\begin{example}[正态菌机数的产生]\label{exam:4.4.3}
    在随机模拟 (蒙特卡洛方法) 中经常需要产生正态分布 $ N ( \mu, \sigma^2 ) $ 的随机数, 但一般计算机软件只具备产生区间 $ (0,1) $ 上的均匀分布随机数的功能, 现在我们要用中心极限定理通过 $ (0,1) $ 上均匀分布的随机数来产生正态分布 $ N ( \mu, \sigma^2 ) $ 的随机数.
    
    设 $ X $ 服从 $ (0,1) $ 上的均匀分布, 则其数学期望与方差分别为 $ 1/2 $ 和 $ 1/12 $.
    由此得 12 个相互独立的 $ (0,1) $ 上均匀分布随机变量和的数学期望与方差分别为 6 和1.
    因此我们可以如下产生正态分布 $ N ( \mu, \sigma^2 ) $ 的随机数.

    \begin{enumerate}
        \item\label{exam:4.4.3.1} 从计算机中产生 12 个 $ (0,1) $ 上均匀分布的随机数, 记为 $ x_1, x_2, \dotsc, x_{12} $.
        \item 计算 $ y = x_1 + x_2 + \dotsb + x_{12} - 6 $, 则由林德贝格-勒维中心极限定理知, 可将 $ y $ 看成来自标准正态分布 $ N (0,1) $ 的一个随机数.
        \item\label{exam:4.4.3.3} 计算 $z = \mu + \sigma y $, 则可将 $ z $ 看成来自标准正态分布 $ N (\mu, \sigma^2) $ 的一个随机数.
        \item 重复 \ref{exam:4.4.3.1}-\ref{exam:4.4.3.3} $n$次, 就可得到 $ N (\mu,\sigma^2 ) $ 分布的 $n$ 个随机数.
    \end{enumerate}
\end{example}

从这个例子可以看出, 由 12 个均匀分布的随机数得到 1 个正态分布的随机数是利用了林德贝格-勒维中心极限定理.

\begin{example}[数值计算中的误差分析]\label{exam:4.4.4}
    在数值计算中, 任何实数 $x$ 都只能用一定位数的小数 $x'$来近似.
    譬如在计算中取5位小数, 第6位以后的小数都用四舍五人的方法舍去, 则 $ \pi = 3.141592654\dots $ 和 $ \ee = 2.718281828\dots $ 的近似数为 $\pi' = 3.14159 $ 和 $ \ee' = 2.71828 $.
    
    现在如果要求 $ n $ 个实数 $ x_i (i = 1, 2, \dotsc, n) $ 的和 $ S $, 在数值计算中, 只能用 $x_i$
\end{example}